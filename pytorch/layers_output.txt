-0.11950311809778214 0.40616291761398315 -1.0405861139297485 -0.8247312903404236 -0.7553362250328064 -0.5809733867645264 1.9869160652160645 1.5380626916885376 1.9869160652160645 0.631237804889679 0.38356146216392517 -0.2013053148984909 1.059766411781311 0.40865761041641235 -1.0199556350708008 -0.18016746640205383
0.3088729679584503 0.22712020576000214 -1.1560556888580322 -0.8460811376571655 -1.0346142053604126 -0.6198352575302124 0.1832081824541092 0.5958430767059326 0.1832081824541092 1.7023664712905884 2.040996551513672 2.422762870788574 1.5244497060775757 1.8674464225769043 -1.232002854347229 -1.194968819618225
labels=tensor([1, 1])

input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.1195  0.4062 -1.0406 -0.8247 -0.7553 -0.5810  1.9869  1.5381  1.9869
  0.3089  0.2271 -1.1561 -0.8461 -1.0346 -0.6198  0.1832  0.5958  0.1832

Columns 10 to 16  0.6312  0.3836 -0.2013  1.0598  0.4087 -1.0200 -0.1802
  1.7024  2.0410  2.4228  1.5244  1.8674 -1.2320 -1.1950
[ CUDAFloatType{1,2,16} ]

out (after input layer) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.2293 -1.3644 -1.2300 -0.2597 -1.3222 -0.3782  0.7953  0.1078  0.9409
 -0.2402 -1.6547 -0.5727 -1.7535 -1.5336 -0.6234  1.3860 -0.1303  1.0718

Columns 10 to 16  1.6465 -0.7220 -1.7378  0.0289  0.7287  0.3491  0.4754
  1.0095  0.0052 -2.2462 -0.6972  0.4118  1.2755 -0.0423
[ CUDAFloatType{1,2,16} ]

cls_tokens -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9  0.9970  0.7997  1.7774  0.2276 -0.8879  1.0277  0.7074  0.4490 -0.6705

Columns 10 to 16 -2.0478  0.8160 -0.6698  0.8994 -0.5684 -1.8305  1.4454
[ CUDAFloatType{1,1,16} ]

out (after class tokens) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  0.9970  0.7997  1.7774  0.2276 -0.8879  1.0277  0.7074  0.4490 -0.6705
  1.2293 -1.3644 -1.2300 -0.2597 -1.3222 -0.3782  0.7953  0.1078  0.9409
 -0.2402 -1.6547 -0.5727 -1.7535 -1.5336 -0.6234  1.3860 -0.1303  1.0718

Columns 10 to 16 -2.0478  0.8160 -0.6698  0.8994 -0.5684 -1.8305  1.4454
  1.6465 -0.7220 -1.7378  0.0289  0.7287  0.3491  0.4754
  1.0095  0.0052 -2.2462 -0.6972  0.4118  1.2755 -0.0423
[ CUDAFloatType{1,3,16} ]

T: input -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  0.9970  0.7997  1.7774  0.2276 -0.8879  1.0277  0.7074  0.4490 -0.6705
  1.2293 -1.3644 -1.2300 -0.2597 -1.3222 -0.3782  0.7953  0.1078  0.9409
 -0.2402 -1.6547 -0.5727 -1.7535 -1.5336 -0.6234  1.3860 -0.1303  1.0718

Columns 10 to 16 -2.0478  0.8160 -0.6698  0.8994 -0.5684 -1.8305  1.4454
  1.6465 -0.7220 -1.7378  0.0289  0.7287  0.3491  0.4754
  1.0095  0.0052 -2.2462 -0.6972  0.4118  1.2755 -0.0423
[ CUDAFloatType{1,3,16} ]

SA: input -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  0.9970  0.7997  1.7774  0.2276 -0.8879  1.0277  0.7074  0.4490 -0.6705
  1.2293 -1.3644 -1.2300 -0.2597 -1.3222 -0.3782  0.7953  0.1078  0.9409
 -0.2402 -1.6547 -0.5727 -1.7535 -1.5336 -0.6234  1.3860 -0.1303  1.0718

Columns 10 to 16 -2.0478  0.8160 -0.6698  0.8994 -0.5684 -1.8305  1.4454
  1.6465 -0.7220 -1.7378  0.0289  0.7287  0.3491  0.4754
  1.0095  0.0052 -2.2462 -0.6972  0.4118  1.2755 -0.0423
[ CUDAFloatType{1,3,16} ]

SA: out (after qkv) -> [1, 3, 48]
(1,.,.) = 
 Columns 1 to 9  2.4072  3.1802  0.1620 -1.6147 -0.0390  1.8117  0.1073  0.9391 -2.5250
 -0.2614  0.8147 -0.8592  0.5779 -0.7731 -0.8903  0.8162 -0.1025  1.2305
  0.4564  0.1004 -0.7696  0.6248  0.2295 -1.3568  0.9677 -0.1748  2.1142

Columns 10 to 18 -2.3724 -1.1861  3.0197 -1.1571 -1.4754 -0.3980 -1.6936  0.8671 -1.5590
  0.8629  0.5638 -0.9955  0.3479  0.3763  0.6133  0.4287  1.9125 -0.5157
  1.8377  1.5987 -1.4006  1.1807  2.0180  0.7109  1.6303  0.9156  0.9649

Columns 19 to 27 -0.6093 -1.9581 -0.6957 -1.0680 -0.5200  0.3751 -0.1830  4.5713 -0.2672
 -0.2224  0.4001 -2.1622 -0.4174 -0.8170 -0.2957  0.7844 -0.9369 -0.5299
  0.1374 -0.1513 -1.7672  0.1708 -1.3407  1.0826  1.2474 -1.8436 -0.7750

Columns 28 to 36  3.0615  0.1099 -0.0881  2.9586  2.3154  0.3383 -0.6399  0.0684 -0.3610
 -0.0911  0.6204 -0.8977 -0.8988  0.3505 -1.2792  3.2929 -1.5261  2.4782
 -0.0665  0.9256 -0.2878 -1.7508  0.2201 -0.9175  3.4449 -1.5560  2.9127

Columns 37 to 45 -0.3963  0.1937 -1.2701 -0.4567 -0.3981 -0.0683 -0.0714 -1.8558  3.2134
  1.4335 -0.5730  2.7133  2.6271 -0.9644 -0.3173  0.4818  1.8480 -0.7389
  1.0353 -0.2144  2.8836  2.8019 -0.5601 -1.6240 -0.4960  1.9929 -0.1251

Columns 46 to 48 -2.8991  2.9090 -0.5263
  0.3447 -0.9575 -0.1380
  1.0085 -0.4793  0.3041
[ CUDAFloatType{1,3,48} ]

SA: out (after view) -> [1, 3, 2, 24]
(1,1,.,.) = 
 Columns 1 to 9  2.4072  3.1802  0.1620 -1.6147 -0.0390  1.8117  0.1073  0.9391 -2.5250
 -0.1830  4.5713 -0.2672  3.0615  0.1099 -0.0881  2.9586  2.3154  0.3383

Columns 10 to 18 -2.3724 -1.1861  3.0197 -1.1571 -1.4754 -0.3980 -1.6936  0.8671 -1.5590
 -0.6399  0.0684 -0.3610 -0.3963  0.1937 -1.2701 -0.4567 -0.3981 -0.0683

Columns 19 to 24 -0.6093 -1.9581 -0.6957 -1.0680 -0.5200  0.3751
 -0.0714 -1.8558  3.2134 -2.8991  2.9090 -0.5263

(1,2,.,.) = 
 Columns 1 to 9 -0.2614  0.8147 -0.8592  0.5779 -0.7731 -0.8903  0.8162 -0.1025  1.2305
  0.7844 -0.9369 -0.5299 -0.0911  0.6204 -0.8977 -0.8988  0.3505 -1.2792

Columns 10 to 18  0.8629  0.5638 -0.9955  0.3479  0.3763  0.6133  0.4287  1.9125 -0.5157
  3.2929 -1.5261  2.4782  1.4335 -0.5730  2.7133  2.6271 -0.9644 -0.3173

Columns 19 to 24 -0.2224  0.4001 -2.1622 -0.4174 -0.8170 -0.2957
  0.4818  1.8480 -0.7389  0.3447 -0.9575 -0.1380

(1,3,.,.) = 
 Columns 1 to 9  0.4564  0.1004 -0.7696  0.6248  0.2295 -1.3568  0.9677 -0.1748  2.1142
  1.2474 -1.8436 -0.7750 -0.0665  0.9256 -0.2878 -1.7508  0.2201 -0.9175

Columns 10 to 18  1.8377  1.5987 -1.4006  1.1807  2.0180  0.7109  1.6303  0.9156  0.9649
  3.4449 -1.5560  2.9127  1.0353 -0.2144  2.8836  2.8019 -0.5601 -1.6240

Columns 19 to 24  0.1374 -0.1513 -1.7672  0.1708 -1.3407  1.0826
 -0.4960  1.9929 -0.1251  1.0085 -0.4793  0.3041
[ CUDAFloatType{1,3,2,24} ]

SA: queries -> [1, 3, 2, 8]
(1,1,.,.) = 
  2.4072  3.1802  0.1620 -1.6147 -0.0390  1.8117  0.1073  0.9391
 -0.1830  4.5713 -0.2672  3.0615  0.1099 -0.0881  2.9586  2.3154

(1,2,.,.) = 
 -0.2614  0.8147 -0.8592  0.5779 -0.7731 -0.8903  0.8162 -0.1025
  0.7844 -0.9369 -0.5299 -0.0911  0.6204 -0.8977 -0.8988  0.3505

(1,3,.,.) = 
  0.4564  0.1004 -0.7696  0.6248  0.2295 -1.3568  0.9677 -0.1748
  1.2474 -1.8436 -0.7750 -0.0665  0.9256 -0.2878 -1.7508  0.2201
[ CUDAFloatType{1,3,2,8} ]

SA: keys -> [1, 3, 2, 8]
(1,1,.,.) = 
 -2.5250 -2.3724 -1.1861  3.0197 -1.1571 -1.4754 -0.3980 -1.6936
  0.3383 -0.6399  0.0684 -0.3610 -0.3963  0.1937 -1.2701 -0.4567

(1,2,.,.) = 
  1.2305  0.8629  0.5638 -0.9955  0.3479  0.3763  0.6133  0.4287
 -1.2792  3.2929 -1.5261  2.4782  1.4335 -0.5730  2.7133  2.6271

(1,3,.,.) = 
  2.1142  1.8377  1.5987 -1.4006  1.1807  2.0180  0.7109  1.6303
 -0.9175  3.4449 -1.5560  2.9127  1.0353 -0.2144  2.8836  2.8019
[ CUDAFloatType{1,3,2,8} ]

SA: values -> [1, 3, 2, 8]
(1,1,.,.) = 
  0.8671 -1.5590 -0.6093 -1.9581 -0.6957 -1.0680 -0.5200  0.3751
 -0.3981 -0.0683 -0.0714 -1.8558  3.2134 -2.8991  2.9090 -0.5263

(1,2,.,.) = 
  1.9125 -0.5157 -0.2224  0.4001 -2.1622 -0.4174 -0.8170 -0.2957
 -0.9644 -0.3173  0.4818  1.8480 -0.7389  0.3447 -0.9575 -0.1380

(1,3,.,.) = 
  0.9156  0.9649  0.1374 -0.1513 -1.7672  0.1708 -1.3407  1.0826
 -0.5601 -1.6240 -0.4960  1.9929 -0.1251  1.0085 -0.4793  0.3041
[ CUDAFloatType{1,3,2,8} ]

SA: energy -> [1, 2, 3, 3]
(1,1,.,.) = 
 -22.9524   8.5415  18.6712
   3.5483  -0.8257  -3.5348
   3.0563  -0.3199  -3.0202

(1,2,.,.) = 
  -8.9862  37.6003  40.4005
   1.4233  -3.6198  -4.1630
   3.2733  -9.3287  -9.8949
[ CUDAFloatType{1,2,3,3} ]

SA: attention -> [1, 2, 3, 3]
(1,1,.,.) = 
  0.0000  0.0736  0.9264
  0.6643  0.2226  0.1131
  0.6065  0.2608  0.1328

(1,2,.,.) = 
  2.9028e-06  3.3180e-01  6.6820e-01
  6.5322e-01  1.8515e-01  1.6164e-01
  9.2592e-01  3.9658e-02  3.4423e-02
[ CUDAFloatType{1,2,3,3} ]

SA: out (after einsum) -> [1, 3, 2, 8]
(1,1,.,.) = 
  0.9890  0.8559  0.1109 -0.1108 -1.7962  0.1274 -1.3021  0.9811
 -0.6942 -1.1904 -0.1716  1.9448 -0.3287  0.7883 -0.6380  0.1574

(1,2,.,.) = 
  1.1053 -1.0414 -0.4387 -1.2289 -1.1433 -0.7831 -0.6789  0.3058
 -0.5291 -0.3659 -0.0376 -0.5480  1.9420 -1.6669  1.6455 -0.3202

(1,3,.,.) = 
  1.1461 -0.9519 -0.4093 -1.1033 -1.2204 -0.7339 -0.7064  0.2941
 -0.4261 -0.1318 -0.0640 -1.5765  2.9417 -2.6360  2.6391 -0.4824
[ CUDAFloatType{1,3,2,8} ]

SA: out (after reshape) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  0.9890  0.8559  0.1109 -0.1108 -1.7962  0.1274 -1.3021  0.9811 -0.6942
  1.1053 -1.0414 -0.4387 -1.2289 -1.1433 -0.7831 -0.6789  0.3058 -0.5291
  1.1461 -0.9519 -0.4093 -1.1033 -1.2204 -0.7339 -0.7064  0.2941 -0.4261

Columns 10 to 16 -1.1904 -0.1716  1.9448 -0.3287  0.7883 -0.6380  0.1574
 -0.3659 -0.0376 -0.5480  1.9420 -1.6669  1.6455 -0.3202
 -0.1318 -0.0640 -1.5765  2.9417 -2.6360  2.6391 -0.4824
[ CUDAFloatType{1,3,16} ]

SA: out (after out()) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  1.5043  0.1974 -0.6621 -2.1107  1.0749 -0.4978 -0.7863 -1.6358  0.6745
  0.0639 -0.0681 -1.4806  2.4677 -1.4248 -0.0361  2.3109 -1.2725 -0.0406
 -0.1374 -0.1405 -1.3179  4.4269 -2.3060  0.5854  3.1694 -0.6110 -0.0996

Columns 10 to 16 -1.2216 -0.2934  2.8539  1.2038  2.8447  0.1726 -0.8812
 -0.1884  0.0058  1.0971 -0.0870 -1.8289  0.2311  1.9598
  0.2776  0.0068  0.7303 -0.2123 -3.3670  0.5052  2.6307
[ CUDAFloatType{1,3,16} ]

SA: final_sum (before returning) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  2.5013  0.9972  1.1152 -1.8831  0.1870  0.5299 -0.0788 -1.1868  0.0040
  1.2932 -1.4325 -2.7106  2.2080 -2.7469 -0.4144  3.1062 -1.1647  0.9003
 -0.3776 -1.7952 -1.8906  2.6734 -3.8396 -0.0380  4.5554 -0.7413  0.9723

Columns 10 to 16 -3.2694  0.5227  2.1841  2.1032  2.2763 -1.6579  0.5641
  1.4581 -0.7161 -0.6407 -0.0581 -1.1001  0.5801  2.4352
  1.2871  0.0120 -1.5160 -0.9095 -2.9552  1.7806  2.5883
[ CUDAFloatType{1,3,16} ]

T: x (after self-attention) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  2.5013  0.9972  1.1152 -1.8831  0.1870  0.5299 -0.0788 -1.1868  0.0040
  1.2932 -1.4325 -2.7106  2.2080 -2.7469 -0.4144  3.1062 -1.1647  0.9003
 -0.3776 -1.7952 -1.8906  2.6734 -3.8396 -0.0380  4.5554 -0.7413  0.9723

Columns 10 to 16 -3.2694  0.5227  2.1841  2.1032  2.2763 -1.6579  0.5641
  1.4581 -0.7161 -0.6407 -0.0581 -1.1001  0.5801  2.4352
  1.2871  0.0120 -1.5160 -0.9095 -2.9552  1.7806  2.5883
[ CUDAFloatType{1,3,16} ]

T: out1 (after linear_1) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  2.5013  0.9972  1.1152  0.0000  0.1870  0.5299  0.0000  0.0000  0.0040
  1.2932  0.0000  0.0000  2.2080  0.0000  0.0000  3.1062  0.0000  0.9003
  0.0000  0.0000  0.0000  2.6734  0.0000  0.0000  4.5554  0.0000  0.9723

Columns 10 to 16  0.0000  0.5227  2.1841  2.1032  2.2763  0.0000  0.5641
  1.4581  0.0000  0.0000  0.0000  0.0000  0.5801  2.4352
  1.2871  0.0120  0.0000  0.0000  0.0000  1.7806  2.5883
[ CUDAFloatType{1,3,16} ]

T: out2 (after linear_2) -> [1, 3, 32]
(1,.,.) = 
 Columns 1 to 9 -3.4111 -1.5560  0.7227 -1.4084  0.4492 -1.1888  0.6922 -2.7459  1.1724
  0.4594 -1.8629 -0.2032  0.4732 -1.7910 -0.2354 -1.1912 -1.1597 -0.9133
  0.9892 -1.8111 -0.5816  1.6368 -2.2071  0.4543 -0.8675 -0.1736 -1.9080

Columns 10 to 18  0.2875 -2.9371 -0.7472 -0.9304  0.8303  2.5799  0.3894 -2.8809 -0.1192
  1.7170  1.9258 -0.4792 -0.2831 -0.6367  0.1302  1.9633 -1.2367 -0.0827
  1.6687  2.8184 -0.1648  0.9581 -1.3518 -0.2057  1.9714 -1.7931  0.6976

Columns 19 to 27 -0.8194 -1.3481  0.5040 -0.5141 -0.2198 -1.7026  0.6198  0.5944 -0.8981
  1.3980 -2.9100  0.8084 -2.7780  1.6793  0.1298 -2.9533  1.1914  2.0358
  1.3601 -3.1982  0.5525 -2.9673  2.2036 -0.2937 -3.5379  1.0950  3.2315

Columns 28 to 32 -0.7969 -0.7963  0.7287 -0.4231  0.2995
 -1.6593 -3.2706 -2.1718 -2.1031 -1.6014
 -1.6567 -2.7595 -2.3097 -1.7303 -1.3279
[ CUDAFloatType{1,3,32} ]

T: out4 (after linear_4) -> [1, 3, 32]
(1,.,.) = 
 Columns 1 to 9  0.0000  0.0000  0.7227  0.0000  0.4492  0.0000  0.6922  0.0000  1.1724
  0.4594  0.0000  0.0000  0.4732  0.0000  0.0000  0.0000  0.0000  0.0000
  0.9892  0.0000  0.0000  1.6368  0.0000  0.4543  0.0000  0.0000  0.0000

Columns 10 to 18  0.2875  0.0000  0.0000  0.0000  0.8303  2.5799  0.3894  0.0000  0.0000
  1.7170  1.9258  0.0000  0.0000  0.0000  0.1302  1.9633  0.0000  0.0000
  1.6687  2.8184  0.0000  0.9581  0.0000  0.0000  1.9714  0.0000  0.6976

Columns 19 to 27  0.0000  0.0000  0.5040  0.0000  0.0000  0.0000  0.6198  0.5944  0.0000
  1.3980  0.0000  0.8084  0.0000  1.6793  0.1298  0.0000  1.1914  2.0358
  1.3601  0.0000  0.5525  0.0000  2.2036  0.0000  0.0000  1.0950  3.2315

Columns 28 to 32  0.0000  0.0000  0.7287  0.0000  0.2995
  0.0000  0.0000  0.0000  0.0000  0.0000
  0.0000  0.0000  0.0000  0.0000  0.0000
[ CUDAFloatType{1,3,32} ]

T: out5 (after linear_5) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9 -0.3883 -1.0703 -0.0514  1.0968 -0.3545  0.1650  0.5229 -0.3288  0.7094
 -1.4613 -2.4866  0.6422 -2.7634 -0.5654 -0.7620  1.0386 -2.1079  2.2974
 -1.5783 -3.3307  1.1894 -5.0732  0.5607  0.3725  0.7181 -2.1185  2.0960

Columns 10 to 16  1.5111  0.5128 -0.9629  1.1867 -0.2969  1.0737  1.0467
 -0.6014 -1.0891  1.6717 -0.8064  1.4312 -1.5721 -0.0502
 -0.3339 -2.7683  1.7295 -1.6370  2.9885 -3.2238  0.3536
[ CUDAFloatType{1,3,16} ]

T: out (after x + out) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  2.1130 -0.0731  1.0638 -0.7862 -0.1675  0.6948  0.4441 -1.5156  0.7134
 -0.1681 -3.9191 -2.0684 -0.5553 -3.3123 -1.1763  4.1447 -3.2727  3.1977
 -1.9559 -5.1259 -0.7012 -2.3998 -3.2790  0.3345  5.2734 -2.8598  3.0682

Columns 10 to 16 -1.7584  1.0355  1.2212  3.2899  1.9794 -0.5841  1.6108
  0.8567 -1.8052  1.0310 -0.8645  0.3310 -0.9919  2.3849
  0.9532 -2.7562  0.2135 -2.5465  0.0334 -1.4431  2.9420
[ CUDAFloatType{1,3,16} ]

T: out (after dropout) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  2.1130 -0.0731  1.0638 -0.7862 -0.1675  0.6948  0.4441 -1.5156  0.7134
 -0.1681 -3.9191 -2.0684 -0.5553 -3.3123 -1.1763  4.1447 -3.2727  3.1977
 -1.9559 -5.1259 -0.7012 -2.3998 -3.2790  0.3345  5.2734 -2.8598  3.0682

Columns 10 to 16 -1.7584  1.0355  1.2212  3.2899  1.9794 -0.5841  1.6108
  0.8567 -1.8052  1.0310 -0.8645  0.3310 -0.9919  2.3849
  0.9532 -2.7562  0.2135 -2.5465  0.0334 -1.4431  2.9420
[ CUDAFloatType{1,3,16} ]

out (after transformer layer) -> [1, 3, 16]
(1,.,.) = 
 Columns 1 to 9  2.1130 -0.0731  1.0638 -0.7862 -0.1675  0.6948  0.4441 -1.5156  0.7134
 -0.1681 -3.9191 -2.0684 -0.5553 -3.3123 -1.1763  4.1447 -3.2727  3.1977
 -1.9559 -5.1259 -0.7012 -2.3998 -3.2790  0.3345  5.2734 -2.8598  3.0682

Columns 10 to 16 -1.7584  1.0355  1.2212  3.2899  1.9794 -0.5841  1.6108
  0.8567 -1.8052  1.0310 -0.8645  0.3310 -0.9919  2.3849
  0.9532 -2.7562  0.2135 -2.5465  0.0334 -1.4431  2.9420
[ CUDAFloatType{1,3,16} ]

out (after out[:, 0]) -> [1, 16]
Columns 1 to 10 2.1130 -0.0731  1.0638 -0.7862 -0.1675  0.6948  0.4441 -1.5156  0.7134 -1.7584

Columns 11 to 16 1.0355  1.2212  3.2899  1.9794 -0.5841  1.6108
[ CUDAFloatType{1,16} ]

out (after out layer 1) -> [1, 5]
 0.8503  2.3983 -1.8537  0.8776  0.2512
[ CUDAFloatType{1,5} ]

out (after squeeze()) -> [1, 5]
 0.8503  2.3983 -1.8537  0.8776  0.2512
[ CUDAFloatType{1,5} ]

final_result (softmax) -> [1, 5]
-1.9942 -0.4462 -4.6981 -1.9668 -2.5933
[ CUDAFloatType{1,5} ]

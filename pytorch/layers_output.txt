-0.11950311809778214 0.40616291761398315 -1.0405861139297485 -0.8247312903404236 -0.7553362250328064 -0.5809733867645264 1.9869160652160645 1.5380626916885376 1.9869160652160645 0.631237804889679 0.38356146216392517 -0.2013053148984909 1.059766411781311 0.40865761041641235 -1.0199556350708008 -0.18016746640205383
input -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -0.1195  0.4062 -1.0406 -0.8247 -0.7553 -0.5810  1.9869  1.5381  1.9869

Columns 10 to 16  0.6312  0.3836 -0.2013  1.0598  0.4087 -1.0200 -0.1802
[ CUDAFloatType{1,1,16} ]
out (after input layer) -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -1.2632  0.4073 -0.0488 -0.7436  0.1413 -1.6926 -0.6131  0.6397 -0.3764

Columns 10 to 16 -1.4310  0.1291  0.8037 -0.4017  0.0811  1.8942  0.4700
[ CUDAFloatType{1,1,16} ]
cls_tokens -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -1.1753 -0.0495 -1.0049  0.4401 -1.4110 -0.0619  0.7493 -1.2401  0.0493

Columns 10 to 16  0.7179  0.1874 -0.1775  0.5011  0.7427 -0.2388 -2.5067
[ CUDAFloatType{1,1,16} ]
out (after class tokens) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -1.1753 -0.0495 -1.0049  0.4401 -1.4110 -0.0619  0.7493 -1.2401  0.0493
 -1.2632  0.4073 -0.0488 -0.7436  0.1413 -1.6926 -0.6131  0.6397 -0.3764

Columns 10 to 16  0.7179  0.1874 -0.1775  0.5011  0.7427 -0.2388 -2.5067
 -1.4310  0.1291  0.8037 -0.4017  0.0811  1.8942  0.4700
[ CUDAFloatType{1,2,16} ]
T: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -1.1753 -0.0495 -1.0049  0.4401 -1.4110 -0.0619  0.7493 -1.2401  0.0493
 -1.2632  0.4073 -0.0488 -0.7436  0.1413 -1.6926 -0.6131  0.6397 -0.3764

Columns 10 to 16  0.7179  0.1874 -0.1775  0.5011  0.7427 -0.2388 -2.5067
 -1.4310  0.1291  0.8037 -0.4017  0.0811  1.8942  0.4700
[ CUDAFloatType{1,2,16} ]
SA: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -1.1753 -0.0495 -1.0049  0.4401 -1.4110 -0.0619  0.7493 -1.2401  0.0493
 -1.2632  0.4073 -0.0488 -0.7436  0.1413 -1.6926 -0.6131  0.6397 -0.3764

Columns 10 to 16  0.7179  0.1874 -0.1775  0.5011  0.7427 -0.2388 -2.5067
 -1.4310  0.1291  0.8037 -0.4017  0.0811  1.8942  0.4700
[ CUDAFloatType{1,2,16} ]
SA: out (after qkv) -> [1, 2, 48]
(1,.,.) = 
 Columns 1 to 9 -1.5656  2.0496  0.0002  1.5567 -0.6812 -1.3411  2.3796 -0.0014  1.3602
  0.4717 -1.2559  0.4640 -1.2972  1.2619  0.1750 -1.7876 -0.0788 -0.2915

Columns 10 to 18 -2.1624 -0.2894 -1.7265  1.1280  1.4459 -1.8493  0.7133 -0.6119 -1.8051
 -0.8880 -0.2086 -0.8192  0.8483  0.6944 -0.8763  0.8519 -0.7543  0.6682

Columns 19 to 27 -1.1406  1.0768 -1.3134  0.2756 -1.0638 -0.6028 -1.4278 -0.0121  0.7579
  0.8565 -0.1984  0.9666  0.9594  1.9530  1.2815  1.9600 -0.7615 -0.3623

Columns 28 to 36  2.2829 -0.9028  1.8995 -2.1606 -0.0318  1.0346  0.2192 -0.3407 -0.9861
 -1.2737  0.5855 -0.2035  1.3293  0.2832 -0.7398 -0.3200 -0.5394  0.6622

Columns 37 to 45  0.5700 -0.8968  1.0499 -0.0905  0.8408  0.7351  0.4331  0.3592 -0.2904
 -0.7123  0.5559 -1.1368  0.0161 -0.9985  1.2789 -0.6860 -2.2145 -1.1769

Columns 46 to 48  1.2936  0.8584  1.1654
 -2.4950 -0.0217 -0.7592
[ CUDAFloatType{1,2,48} ]
SA: queries -> [1, 2, 2, 8]
(1,1,.,.) = 
 -1.5656  2.0496  0.0002  1.5567 -0.6812 -1.3411  2.3796 -0.0014
 -1.4278 -0.0121  0.7579  2.2829 -0.9028  1.8995 -2.1606 -0.0318

(1,2,.,.) = 
  0.4717 -1.2559  0.4640 -1.2972  1.2619  0.1750 -1.7876 -0.0788
  1.9600 -0.7615 -0.3623 -1.2737  0.5855 -0.2035  1.3293  0.2832
[ CUDAFloatType{1,2,2,8} ]
SA: keys -> [1, 2, 2, 8]
(1,1,.,.) = 
  1.3602 -2.1624 -0.2894 -1.7265  1.1280  1.4459 -1.8493  0.7133
  1.0346  0.2192 -0.3407 -0.9861  0.5700 -0.8968  1.0499 -0.0905

(1,2,.,.) = 
 -0.2915 -0.8880 -0.2086 -0.8192  0.8483  0.6944 -0.8763  0.8519
 -0.7398 -0.3200 -0.5394  0.6622 -0.7123  0.5559 -1.1368  0.0161
[ CUDAFloatType{1,2,2,8} ]
SA: values -> [1, 2, 2, 8]
(1,1,.,.) = 
 -0.6119 -1.8051 -1.1406  1.0768 -1.3134  0.2756 -1.0638 -0.6028
  0.8408  0.7351  0.4331  0.3592 -0.2904  1.2936  0.8584  1.1654

(1,2,.,.) = 
 -0.7543  0.6682  0.8565 -0.1984  0.9666  0.9594  1.9530  1.2815
 -0.9985  1.2789 -0.6860 -2.2145 -1.1769 -2.4950 -0.0217 -0.7592
[ CUDAFloatType{1,2,2,8} ]
SA: energy -> [1, 2, 2, 2]
(1,1,.,.) = 
 -16.3581  -6.2345
  10.3889   4.6351

(1,2,.,.) = 
 -8.4728  6.3177
  5.1265 -3.8911
[ CUDAFloatType{1,2,2,2} ]
SA: attention -> [1, 2, 2, 2]
(1,1,.,.) = 
  0.0737  0.9263
  0.8082  0.1918

(1,2,.,.) = 
  0.0242  0.9758
  0.9050  0.0950
[ CUDAFloatType{1,2,2,2} ]
SA: out (after einsum) -> [1, 2, 2, 8]
(1,1,.,.) = 
 -0.7438  0.4858  0.7093 -0.1044  0.7985  0.9090  1.7306  1.1426
 -0.9540  1.2657 -0.6589 -2.1523 -1.1555 -2.4034 -0.0004 -0.7127

(1,2,.,.) = 
 -0.6392 -1.3307 -0.7576  0.8323 -0.8761  0.4067 -0.4853 -0.2414
  0.6661  0.7867  0.3268  0.1148 -0.3746  0.9338  0.7748  0.9826
[ CUDAFloatType{1,2,2,8} ]
SA: out (after reshape) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.7438  0.4858  0.7093 -0.1044  0.7985  0.9090  1.7306  1.1426 -0.9540
 -0.6392 -1.3307 -0.7576  0.8323 -0.8761  0.4067 -0.4853 -0.2414  0.6661

Columns 10 to 16  1.2657 -0.6589 -2.1523 -1.1555 -2.4034 -0.0004 -0.7127
  0.7867  0.3268  0.1148 -0.3746  0.9338  0.7748  0.9826
[ CUDAFloatType{1,2,16} ]
SA: out (after out()) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.4084  1.4424 -0.2850  2.1722 -0.8800 -1.7619 -0.2343  0.4223  0.1866
  0.5035  0.2722 -0.3334 -0.2060 -0.9064  0.0035 -1.2054 -0.3406 -0.7667

Columns 10 to 16  2.1947 -1.1377 -4.4623 -2.9624 -0.4898  0.1215  1.2884
  0.0716  0.2649 -0.0410  0.4297 -0.0688  1.1862 -1.5432
[ CUDAFloatType{1,2,16} ]
SA: final_sum (before returning) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.2331  1.3929 -1.2899  2.6123 -2.2910 -1.8238  0.5150 -0.8178  0.2359
 -0.7597  0.6795 -0.3822 -0.9496 -0.7651 -1.6891 -1.8185  0.2992 -1.1431

Columns 10 to 16  2.9126 -0.9503 -4.6399 -2.4613  0.2529 -0.1173 -1.2183
 -1.3594  0.3940  0.7627  0.0280  0.0123  3.0803 -1.0731
[ CUDAFloatType{1,2,16} ]
T: x (after self-attention) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.2331  1.3929 -1.2899  2.6123 -2.2910 -1.8238  0.5150 -0.8178  0.2359
 -0.7597  0.6795 -0.3822 -0.9496 -0.7651 -1.6891 -1.8185  0.2992 -1.1431

Columns 10 to 16  2.9126 -0.9503 -4.6399 -2.4613  0.2529 -0.1173 -1.2183
 -1.3594  0.3940  0.7627  0.0280  0.0123  3.0803 -1.0731
[ CUDAFloatType{1,2,16} ]
T: out1 (after linear_1) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.2331  1.3929  0.0000  2.6123  0.0000  0.0000  0.5150  0.0000  0.2359
  0.0000  0.6795  0.0000  0.0000  0.0000  0.0000  0.0000  0.2992  0.0000

Columns 10 to 16  2.9126  0.0000  0.0000  0.0000  0.2529  0.0000  0.0000
  0.0000  0.3940  0.7627  0.0280  0.0123  3.0803  0.0000
[ CUDAFloatType{1,2,16} ]
T: out2 (after linear_2) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  0.5373  0.4379  0.6047 -3.4956  0.4572 -7.2181  0.7456  0.0484  0.5373
  0.2352  0.0721  0.6395 -0.5897 -0.6503 -0.2259  0.9499  0.1349  0.4864

Columns 10 to 18  0.5369  1.4220 -4.5299 -1.6663 -0.1637  0.2535  0.0895 -5.3035  1.0691
 -1.4705 -0.6496  0.2109 -0.8632 -2.2116 -0.3881 -0.9095  0.2755 -0.3441

Columns 19 to 27  0.2223 -1.8111 -2.6809  0.2767 -3.3950 -0.0989  0.3244  0.3790 -2.9182
  0.2890 -1.4992 -0.0184 -0.3743 -0.3509 -0.1561 -0.2493 -0.2719 -0.1173

Columns 28 to 32 -0.2043 -6.6298  0.4495 -3.4180  0.0933
 -1.2165  0.1806 -0.6406 -0.2072  0.5236
[ CUDAFloatType{1,2,32} ]
T: out4 (after linear_4) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  0.5373  0.4379  0.6047  0.0000  0.4572  0.0000  0.7456  0.0484  0.5373
  0.2352  0.0721  0.6395  0.0000  0.0000  0.0000  0.9499  0.1349  0.4864

Columns 10 to 18  0.5369  1.4220  0.0000  0.0000  0.0000  0.2535  0.0895  0.0000  1.0691
  0.0000  0.0000  0.2109  0.0000  0.0000  0.0000  0.0000  0.2755  0.0000

Columns 19 to 27  0.2223  0.0000  0.0000  0.2767  0.0000  0.0000  0.3244  0.3790  0.0000
  0.2890  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000

Columns 28 to 32  0.0000  0.0000  0.4495  0.0000  0.0933
  0.0000  0.1806  0.0000  0.0000  0.5236
[ CUDAFloatType{1,2,32} ]
T: out5 (after linear_5) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.4759 -1.0479  0.8909 -1.2721  0.3357 -0.3656  1.1047  0.1579 -0.4405
  0.6947 -0.3559  0.7269 -0.0482  0.4275 -0.2518  1.0729  0.6131  0.0080

Columns 10 to 16  0.0623  0.6481  0.6112 -0.2113 -0.1911  0.0628  0.7968
  0.0858  0.6966  0.2287 -0.3580 -0.6696 -0.2154  0.0171
[ CUDAFloatType{1,2,16} ]
T: out (after x + out) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.7090  0.3450 -0.3990  1.3402 -1.9553 -2.1894  1.6196 -0.6599 -0.2046
 -0.0650  0.3236  0.3447 -0.9977 -0.3375 -1.9409 -0.7456  0.9123 -1.1351

Columns 10 to 16  2.9749 -0.3022 -4.0287 -2.6726  0.0618 -0.0545 -0.4215
 -1.2736  1.0906  0.9914 -0.3300 -0.6572  2.8649 -1.0560
[ CUDAFloatType{1,2,16} ]
T: out (after dropout) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.7090  0.3450 -0.3990  1.3402 -1.9553 -2.1894  1.6196 -0.6599 -0.2046
 -0.0650  0.3236  0.3447 -0.9977 -0.3375 -1.9409 -0.7456  0.9123 -1.1351

Columns 10 to 16  2.9749 -0.3022 -4.0287 -2.6726  0.0618 -0.0545 -0.4215
 -1.2736  1.0906  0.9914 -0.3300 -0.6572  2.8649 -1.0560
[ CUDAFloatType{1,2,16} ]
out (after transformer layer) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.7090  0.3450 -0.3990  1.3402 -1.9553 -2.1894  1.6196 -0.6599 -0.2046
 -0.0650  0.3236  0.3447 -0.9977 -0.3375 -1.9409 -0.7456  0.9123 -1.1351

Columns 10 to 16  2.9749 -0.3022 -4.0287 -2.6726  0.0618 -0.0545 -0.4215
 -1.2736  1.0906  0.9914 -0.3300 -0.6572  2.8649 -1.0560
[ CUDAFloatType{1,2,16} ]
out (after out[:, 0]) -> [1, 16]
Columns 1 to 10 0.7090  0.3450 -0.3990  1.3402 -1.9553 -2.1894  1.6196 -0.6599 -0.2046  2.9749

Columns 11 to 16-0.3022 -4.0287 -2.6726  0.0618 -0.0545 -0.4215
[ CUDAFloatType{1,16} ]
out (after out layer 1) -> [1, 5]
 1.4120  1.1659 -1.4495 -0.2031 -0.3747
[ CUDAFloatType{1,5} ]
out (after squeeze()) -> [1, 5]
 1.4120  1.1659 -1.4495 -0.2031 -0.3747
[ CUDAFloatType{1,5} ]
final_result (softmax) -> [1, 5]
-0.7909 -1.0371 -3.6524 -2.4060 -2.5776
[ CUDAFloatType{1,5} ]

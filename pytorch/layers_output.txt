[-0.11950311809778214, 0.40616291761398315, -1.0405861139297485, -0.8247312903404236, -0.7553362250328064, -0.5809733867645264, 1.9869160652160645, 1.5380626916885376, 1.9869160652160645, 0.631237804889679, 0.38356146216392517, -0.2013053148984909, 1.059766411781311, 0.40865761041641235, -1.0199556350708008, -0.18016746640205383]

input -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -0.1195  0.4062 -1.0406 -0.8247 -0.7553 -0.5810  1.9869  1.5381  1.9869

Columns 10 to 16  0.6312  0.3836 -0.2013  1.0598  0.4087 -1.0200 -0.1802
[ CUDAFloatType{1,1,16} ]

out (after input layer) -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -0.2691 -1.0440  0.0806 -0.5658 -0.2457  1.5042  0.0557  1.3381 -0.6900

Columns 10 to 16  0.5883 -0.0728 -0.7283  2.1384  1.2890  1.2185 -0.6188
[ CUDAFloatType{1,1,16} ]

cls_tokens -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
[ CUDAFloatType{1,1,16} ]

out (after class tokens) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -0.2691 -1.0440  0.0806 -0.5658 -0.2457  1.5042  0.0557  1.3381 -0.6900

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
  0.5883 -0.0728 -0.7283  2.1384  1.2890  1.2185 -0.6188
[ CUDAFloatType{1,2,16} ]

T: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -0.2691 -1.0440  0.0806 -0.5658 -0.2457  1.5042  0.0557  1.3381 -0.6900

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
  0.5883 -0.0728 -0.7283  2.1384  1.2890  1.2185 -0.6188
[ CUDAFloatType{1,2,16} ]

SA: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -0.2691 -1.0440  0.0806 -0.5658 -0.2457  1.5042  0.0557  1.3381 -0.6900

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
  0.5883 -0.0728 -0.7283  2.1384  1.2890  1.2185 -0.6188
[ CUDAFloatType{1,2,16} ]

SA: out (after qkv) -> [1, 2, 48]
(1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.2641 -0.8061  0.0883 -0.3862  0.2050  0.2998 -0.5885 -0.2078 -1.7687

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
  0.1161 -1.0880  0.8888 -1.6696 -0.0787 -0.8609  1.3666 -0.8287 -2.3701

Columns 19 to 27 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438  0.0577  0.2429 -1.1539
  2.3048  1.1349  1.2735  3.1099  1.2620 -1.5907 -0.5922 -0.1378 -0.2613

Columns 28 to 36  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179 -0.4862  0.5505 -1.1303
  0.4877  0.5072 -0.3038  0.2035  0.9580 -0.0383  0.5307 -1.4180  1.3098

Columns 37 to 45 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444  0.1004 -1.4107  0.7586
  1.1671 -0.8963 -0.4114  1.0577 -0.1040 -1.4889  0.1524 -1.3500 -0.4473

Columns 46 to 48 -0.9349  1.4582 -0.2389
  0.3465  2.3173  0.3244
[ CUDAFloatType{1,2,48} ]

SA: out (after view) -> [1, 2, 2, 24]
(1,1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444

Columns 19 to 24 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
 Columns 1 to 9  0.2641 -0.8061  0.0883 -0.3862  0.2050  0.2998 -0.5885 -0.2078 -1.7687
 -0.5922 -0.1378 -0.2613  0.4877  0.5072 -0.3038  0.2035  0.9580 -0.0383

Columns 10 to 18  0.1161 -1.0880  0.8888 -1.6696 -0.0787 -0.8609  1.3666 -0.8287 -2.3701
  0.5307 -1.4180  1.3098  1.1671 -0.8963 -0.4114  1.0577 -0.1040 -1.4889

Columns 19 to 24  2.3048  1.1349  1.2735  3.1099  1.2620 -1.5907
  0.1524 -1.3500 -0.4473  0.3465  2.3173  0.3244
[ CUDAFloatType{1,2,2,24} ]

SA: queries -> [1, 2, 2, 8]
(1,1,.,.) = 
  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043

(1,2,.,.) = 
  0.2641 -0.8061  0.0883 -0.3862  0.2050  0.2998 -0.5885 -0.2078
 -0.5922 -0.1378 -0.2613  0.4877  0.5072 -0.3038  0.2035  0.9580
[ CUDAFloatType{1,2,2,8} ]

SA: keys -> [1, 2, 2, 8]
(1,1,.,.) = 
 -1.5802  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811
  0.1179 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086

(1,2,.,.) = 
 -1.7687  0.1161 -1.0880  0.8888 -1.6696 -0.0787 -0.8609  1.3666
 -0.0383  0.5307 -1.4180  1.3098  1.1671 -0.8963 -0.4114  1.0577
[ CUDAFloatType{1,2,2,8} ]

SA: values -> [1, 2, 2, 8]
(1,1,.,.) = 
 -0.8740  0.1034 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
 -0.1977 -0.1444  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
 -0.8287 -2.3701  2.3048  1.1349  1.2735  3.1099  1.2620 -1.5907
 -0.1040 -1.4889  0.1524 -1.3500 -0.4473  0.3465  2.3173  0.3244
[ CUDAFloatType{1,2,2,8} ]

SA: energy -> [1, 2, 2, 2]
(1,1,.,.) = 
 -10.1156 -12.5313
  -1.0917  -1.1433

(1,2,.,.) = 
  -9.8000  12.4513
  -2.2374   2.7528
[ CUDAFloatType{1,2,2,2} ]

SA: attention -> [1, 2, 2, 2]
(1,1,.,.) = 
  0.6466  0.3534
  0.5032  0.4968

(1,2,.,.) = 
  0.0038  0.9962
  0.2231  0.7769
[ CUDAFloatType{1,2,2,2} ]

SA: out (after einsum) -> [1, 2, 2, 8]
(1,1,.,.) = 
 -0.8580 -0.7708  0.3218 -0.3160  1.1837  2.0826  0.3937 -0.3399
 -0.1044 -1.4837  0.1522 -1.3502 -0.4427  0.3416  2.3141  0.3222

(1,2,.,.) = 
 -0.8515 -1.1254  0.7614  0.0056  1.2036  2.3104  0.5862 -0.6172
 -0.1249 -1.1889  0.1408 -1.3635 -0.1782  0.0606  2.1256  0.1987
[ CUDAFloatType{1,2,2,8} ]

SA: out (after reshape) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.8580 -0.7708  0.3218 -0.3160  1.1837  2.0826  0.3937 -0.3399 -0.1044
 -0.8515 -1.1254  0.7614  0.0056  1.2036  2.3104  0.5862 -0.6172 -0.1249

Columns 10 to 16 -1.4837  0.1522 -1.3502 -0.4427  0.3416  2.3141  0.3222
 -1.1889  0.1408 -1.3635 -0.1782  0.0606  2.1256  0.1987
[ CUDAFloatType{1,2,16} ]

SA: out (after out()) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.4681 -3.2379  1.0593  2.4956 -2.3531  0.2020  0.1035 -0.1914  1.6102
 -0.5141 -3.3224  1.6821  2.9332 -2.2066  0.6692 -0.0466 -0.1424  1.5561

Columns 10 to 16  0.8773  2.5619  0.7069 -0.3339  2.7930 -0.5303 -0.6041
  0.7917  2.7481  0.7934 -0.1789  3.6105 -0.8391 -0.8354
[ CUDAFloatType{1,2,16} ]

SA: final_sum (before returning) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.2708 -3.0151  1.5812  3.2134 -0.5804  0.5840 -0.6685  0.8760  0.5660
 -0.7832 -4.3665  1.7627  2.3674 -2.4523  2.1734  0.0091  1.1957  0.8661

Columns 10 to 16 -0.2800  2.1465 -1.3897  0.5037  2.3614  0.3136 -1.2242
  1.3800  2.6754  0.0651  1.9595  4.8995  0.3793 -1.4541
[ CUDAFloatType{1,2,16} ]

T: x (after self-attention) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.2708 -3.0151  1.5812  3.2134 -0.5804  0.5840 -0.6685  0.8760  0.5660
 -0.7832 -4.3665  1.7627  2.3674 -2.4523  2.1734  0.0091  1.1957  0.8661

Columns 10 to 16 -0.2800  2.1465 -1.3897  0.5037  2.3614  0.3136 -1.2242
  1.3800  2.6754  0.0651  1.9595  4.8995  0.3793 -1.4541
[ CUDAFloatType{1,2,16} ]

T: out1 (after linear_1) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.2708  0.0000  1.5812  3.2134  0.0000  0.5840  0.0000  0.8760  0.5660
  0.0000  0.0000  1.7627  2.3674  0.0000  2.1734  0.0091  1.1957  0.8661

Columns 10 to 16  0.0000  2.1465  0.0000  0.5037  2.3614  0.3136  0.0000
  1.3800  2.6754  0.0651  1.9595  4.8995  0.3793  0.0000
[ CUDAFloatType{1,2,16} ]

T: out2 (after linear_2) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9 -2.2304 -0.1966  0.2040 -1.7403  1.0341  0.1555  0.6525 -3.9435  0.3074
 -4.4144  2.3045  2.4609 -3.0588  2.8215 -0.3188  1.4486 -7.1085 -1.4734

Columns 10 to 18  0.2712 -0.5747 -1.7350 -5.3603 -0.9171 -1.0134 -1.6101  0.3368 -3.7914
  2.2195 -0.9596 -2.4182 -5.6230 -3.1713 -1.0570 -3.5551  0.6859 -6.4345

Columns 19 to 27 -3.6036  0.9492  1.6259 -1.7536  0.9574  0.1862 -1.0161 -0.0133 -4.2046
 -5.4570 -1.5760  2.8353 -3.7645  1.6193  0.5153  1.9535  2.2455 -6.6350

Columns 28 to 32 -0.8663 -4.0097 -3.5002  0.6875  0.3717
 -0.7179 -7.0723 -7.4250 -0.8117 -1.7881
[ CUDAFloatType{1,2,32} ]

T: out4 (after linear_4) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  0.0000  0.0000  0.2040  0.0000  1.0341  0.1555  0.6525  0.0000  0.3074
  0.0000  2.3045  2.4609  0.0000  2.8215  0.0000  1.4486  0.0000  0.0000

Columns 10 to 18  0.2712  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3368  0.0000
  2.2195  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.6859  0.0000

Columns 19 to 27  0.0000  0.9492  1.6259  0.0000  0.9574  0.1862  0.0000  0.0000  0.0000
  0.0000  0.0000  2.8353  0.0000  1.6193  0.5153  1.9535  2.2455  0.0000

Columns 28 to 32  0.0000  0.0000  0.0000  0.6875  0.3717
  0.0000  0.0000  0.0000  0.0000  0.0000
[ CUDAFloatType{1,2,32} ]

T: out5 (after linear_5) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.9349 -0.0455  0.4683 -1.2150  0.2651 -0.0041 -0.3301 -0.0700  0.9039
 -0.1112  1.1140 -1.1881 -4.1655 -0.3067 -1.3525 -1.2813  0.0213  4.3950

Columns 10 to 16 -0.8509  0.8138  1.3895 -0.3265 -1.1021  0.3080  1.2109
 -2.6676  2.6222  1.0799 -3.7742  0.4109  2.0156  1.5884
[ CUDAFloatType{1,2,16} ]

T: out (after x + out) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.3359 -3.0605  2.0496  1.9984 -0.3153  0.5799 -0.9986  0.8061  1.4699
 -0.8944 -3.2525  0.5747 -1.7982 -2.7590  0.8209 -1.2722  1.2170  5.2611

Columns 10 to 16 -1.1309  2.9603 -0.0002  0.1772  1.2593  0.6216 -0.0133
 -1.2876  5.2976  1.1450 -1.8147  5.3105  2.3949  0.1342
[ CUDAFloatType{1,2,16} ]

T: out (after dropout) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.3359 -3.0605  2.0496  1.9984 -0.3153  0.5799 -0.9986  0.8061  1.4699
 -0.8944 -3.2525  0.5747 -1.7982 -2.7590  0.8209 -1.2722  1.2170  5.2611

Columns 10 to 16 -1.1309  2.9603 -0.0002  0.1772  1.2593  0.6216 -0.0133
 -1.2876  5.2976  1.1450 -1.8147  5.3105  2.3949  0.1342
[ CUDAFloatType{1,2,16} ]

out (after transformer layer) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.3359 -3.0605  2.0496  1.9984 -0.3153  0.5799 -0.9986  0.8061  1.4699
 -0.8944 -3.2525  0.5747 -1.7982 -2.7590  0.8209 -1.2722  1.2170  5.2611

Columns 10 to 16 -1.1309  2.9603 -0.0002  0.1772  1.2593  0.6216 -0.0133
 -1.2876  5.2976  1.1450 -1.8147  5.3105  2.3949  0.1342
[ CUDAFloatType{1,2,16} ]

out (after out[:, 0]) -> [1, 16]
Columns 1 to 10 0.3359 -3.0605  2.0496  1.9984 -0.3153  0.5799 -0.9986  0.8061  1.4699 -1.1309

Columns 11 to 16 2.9603 -0.0002  0.1772  1.2593  0.6216 -0.0133
[ CUDAFloatType{1,16} ]

out (after out layer 1) -> [1, 5]
 1.5646  1.5199 -1.2990  0.2428  0.2441
[ CUDAFloatType{1,5} ]

out (after squeeze()) -> [1, 5]
 1.5646  1.5199 -1.2990  0.2428  0.2441
[ CUDAFloatType{1,5} ]

final_result (softmax) -> [1, 5]
-0.9349 -0.9796 -3.7985 -2.2567 -2.2554
[ CUDAFloatType{1,5} ]

input -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9  0.3089  0.2271 -1.1561 -0.8461 -1.0346 -0.6198  0.1832  0.5958  0.1832

Columns 10 to 16  1.7024  2.0410  2.4228  1.5244  1.8674 -1.2320 -1.1950
[ CUDAFloatType{1,1,16} ]

out (after input layer) -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9  0.6430 -1.1345  0.5693  0.3353 -0.9118  1.8125  2.5611  0.8017 -1.6979

Columns 10 to 16  1.4390 -0.3185 -0.7994  1.8858  1.0041  0.9842 -0.2332
[ CUDAFloatType{1,1,16} ]

cls_tokens -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
[ CUDAFloatType{1,1,16} ]

out (after class tokens) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
  0.6430 -1.1345  0.5693  0.3353 -0.9118  1.8125  2.5611  0.8017 -1.6979

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
  1.4390 -0.3185 -0.7994  1.8858  1.0041  0.9842 -0.2332
[ CUDAFloatType{1,2,16} ]

T: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
  0.6430 -1.1345  0.5693  0.3353 -0.9118  1.8125  2.5611  0.8017 -1.6979

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
  1.4390 -0.3185 -0.7994  1.8858  1.0041  0.9842 -0.2332
[ CUDAFloatType{1,2,16} ]

SA: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
  0.6430 -1.1345  0.5693  0.3353 -0.9118  1.8125  2.5611  0.8017 -1.6979

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
  1.4390 -0.3185 -0.7994  1.8858  1.0041  0.9842 -0.2332
[ CUDAFloatType{1,2,16} ]

SA: out (after qkv) -> [1, 2, 48]
(1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.2091 -1.3350  0.1088 -0.1234 -0.3531  0.7275 -0.9672 -0.3346 -1.6603

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
  0.1576 -0.9295  1.3142 -1.1350  0.0417 -0.6679  1.6317  0.6245 -3.3602

Columns 19 to 27 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438  0.0577  0.2429 -1.1539
  1.1537  3.3143  1.7533  3.1412  1.9737 -3.3588 -1.2711  0.2361  0.2461

Columns 28 to 36  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179 -0.4862  0.5505 -1.1303
  0.1306 -0.4886  0.2478  0.7067  0.0863 -0.0890  0.2026 -1.1990  0.5457

Columns 37 to 45 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444  0.1004 -1.4107  0.7586
  1.7774 -1.2565 -0.8754  0.4706 -0.5830 -2.0058 -0.3280 -1.4138 -0.3216

Columns 46 to 48 -0.9349  1.4582 -0.2389
  0.6358  1.6240  0.5918
[ CUDAFloatType{1,2,48} ]

SA: out (after view) -> [1, 2, 2, 24]
(1,1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444

Columns 19 to 24 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
 Columns 1 to 9  0.2091 -1.3350  0.1088 -0.1234 -0.3531  0.7275 -0.9672 -0.3346 -1.6603
 -1.2711  0.2361  0.2461  0.1306 -0.4886  0.2478  0.7067  0.0863 -0.0890

Columns 10 to 18  0.1576 -0.9295  1.3142 -1.1350  0.0417 -0.6679  1.6317  0.6245 -3.3602
  0.2026 -1.1990  0.5457  1.7774 -1.2565 -0.8754  0.4706 -0.5830 -2.0058

Columns 19 to 24  1.1537  3.3143  1.7533  3.1412  1.9737 -3.3588
 -0.3280 -1.4138 -0.3216  0.6358  1.6240  0.5918
[ CUDAFloatType{1,2,2,24} ]

SA: queries -> [1, 2, 2, 8]
(1,1,.,.) = 
  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043

(1,2,.,.) = 
  0.2091 -1.3350  0.1088 -0.1234 -0.3531  0.7275 -0.9672 -0.3346
 -1.2711  0.2361  0.2461  0.1306 -0.4886  0.2478  0.7067  0.0863
[ CUDAFloatType{1,2,2,8} ]

SA: keys -> [1, 2, 2, 8]
(1,1,.,.) = 
 -1.5802  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811
  0.1179 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086

(1,2,.,.) = 
 -1.6603  0.1576 -0.9295  1.3142 -1.1350  0.0417 -0.6679  1.6317
 -0.0890  0.2026 -1.1990  0.5457  1.7774 -1.2565 -0.8754  0.4706
[ CUDAFloatType{1,2,2,8} ]

SA: values -> [1, 2, 2, 8]
(1,1,.,.) = 
 -0.8740  0.1034 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
 -0.1977 -0.1444  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
  0.6245 -3.3602  1.1537  3.3143  1.7533  3.1412  1.9737 -3.3588
 -0.5830 -2.0058 -0.3280 -1.4138 -0.3216  0.6358  1.6240  0.5918
[ CUDAFloatType{1,2,2,8} ]

SA: energy -> [1, 2, 2, 2]
(1,1,.,.) = 
 -10.1156 -11.3046
  -0.2510  -0.2898

(1,2,.,.) = 
 -9.8000  9.6680
 -0.0131 -1.8206
[ CUDAFloatType{1,2,2,2} ]

SA: attention -> [1, 2, 2, 2]
(1,1,.,.) = 
  0.5738  0.4262
  0.5024  0.4976

(1,2,.,.) = 
  0.0076  0.9924
  0.6111  0.3889
[ CUDAFloatType{1,2,2,2} ]

SA: out (after einsum) -> [1, 2, 2, 8]
(1,1,.,.) = 
 -0.2353 -1.3729  0.0544  0.7763  1.3983  2.2116  0.7948 -1.2344
 -0.5800 -1.9916 -0.3248 -1.4137 -0.3134  0.6238  1.6227  0.5855

(1,2,.,.) = 
 -0.1284 -1.6200  0.1911  1.0919  1.4424  2.3272  0.9414 -1.4985
 -0.3475 -0.8683 -0.0662 -1.4119  0.3385 -0.3240  1.5227  0.0842
[ CUDAFloatType{1,2,2,8} ]

SA: out (after reshape) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.2353 -1.3729  0.0544  0.7763  1.3983  2.2116  0.7948 -1.2344 -0.5800
 -0.1284 -1.6200  0.1911  1.0919  1.4424  2.3272  0.9414 -1.4985 -0.3475

Columns 10 to 16 -1.9916 -0.3248 -1.4137 -0.3134  0.6238  1.6227  0.5855
 -0.8683 -0.0662 -1.4119  0.3385 -0.3240  1.5227  0.0842
[ CUDAFloatType{1,2,16} ]

SA: out (after out()) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.7993 -3.9121  2.3563  3.3779 -0.7671  0.6179 -0.2637 -0.0509  0.8505
 -1.0591 -3.3052  2.7619  3.2977 -1.0717  1.5460 -0.1023  0.3042  0.7095

Columns 10 to 16  0.9425  2.8678  1.1034  0.0093  3.4022 -0.6866 -0.9137
  0.6087  2.7345  0.8916  0.4797  4.1232 -1.4034 -1.5074
[ CUDAFloatType{1,2,16} ]

SA: final_sum (before returning) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.9396 -3.6893  2.8782  4.0957  1.0055  0.9998 -1.0357  1.0166 -0.1937
 -0.4161 -4.4397  3.3312  3.6330 -1.9835  3.3585  2.4588  1.1059 -0.9884

Columns 10 to 16 -0.2148  2.4524 -0.9932  0.8468  2.9706  0.1573 -1.5339
  2.0477  2.4159  0.0922  2.3654  5.1273 -0.4192 -1.7405
[ CUDAFloatType{1,2,16} ]

T: x (after self-attention) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.9396 -3.6893  2.8782  4.0957  1.0055  0.9998 -1.0357  1.0166 -0.1937
 -0.4161 -4.4397  3.3312  3.6330 -1.9835  3.3585  2.4588  1.1059 -0.9884

Columns 10 to 16 -0.2148  2.4524 -0.9932  0.8468  2.9706  0.1573 -1.5339
  2.0477  2.4159  0.0922  2.3654  5.1273 -0.4192 -1.7405
[ CUDAFloatType{1,2,16} ]

T: out1 (after linear_1) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.9396  0.0000  2.8782  4.0957  1.0055  0.9998  0.0000  1.0166  0.0000
  0.0000  0.0000  3.3312  3.6330  0.0000  3.3585  2.4588  1.1059  0.0000

Columns 10 to 16  0.0000  2.4524  0.0000  0.8468  2.9706  0.1573  0.0000
  2.0477  2.4159  0.0922  2.3654  5.1273  0.0000  0.0000
[ CUDAFloatType{1,2,16} ]

T: out2 (after linear_2) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9 -2.6773 -0.8878  0.3725 -2.3143  1.4322  0.2821  1.5612 -5.1577  1.1179
 -4.6871  0.3855  4.0174 -2.5806  4.7718 -0.9021  1.3693 -7.9032 -1.7598

Columns 10 to 18 -0.1053 -0.9622 -2.1931 -7.9417 -1.1842 -0.6692 -1.5201 -0.6244 -4.2618
  2.9917 -1.6809 -0.7218 -10.3165 -3.4132 -0.9712 -3.6463  0.4349 -5.3864

Columns 19 to 27 -5.1259  1.0191  2.2980 -1.8603  0.9739  0.6764 -1.7963  0.3115 -5.0194
 -6.6538 -2.3381  4.0849 -3.4788  1.9947  0.2924  0.1875  2.7336 -7.0113

Columns 28 to 32 -1.1083 -5.0720 -4.5385  0.8229  0.3399
 -1.3331 -6.6212 -8.5849 -1.1973 -3.1131
[ CUDAFloatType{1,2,32} ]

T: out4 (after linear_4) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  0.0000  0.0000  0.3725  0.0000  1.4322  0.2821  1.5612  0.0000  1.1179
  0.0000  0.3855  4.0174  0.0000  4.7718  0.0000  1.3693  0.0000  0.0000

Columns 10 to 18  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000
  2.9917  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.4349  0.0000

Columns 19 to 27  0.0000  1.0191  2.2980  0.0000  0.9739  0.6764  0.0000  0.3115  0.0000
  0.0000  0.0000  4.0849  0.0000  1.9947  0.2924  0.1875  2.7336  0.0000

Columns 28 to 32  0.0000  0.0000  0.0000  0.8229  0.3399
  0.0000  0.0000  0.0000  0.0000  0.0000
[ CUDAFloatType{1,2,32} ]

T: out5 (after linear_5) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -1.6274  0.3360  0.8387 -1.7334  0.7006  0.1382 -0.2545  0.2394  1.2618
 -0.0813  1.7792 -2.1435 -5.3594 -1.8863 -0.7932 -2.2407 -1.1385  4.5888

Columns 10 to 16 -1.2735  1.4781  1.7613 -0.6469 -1.4565  0.3787  1.9311
 -2.8423  1.9022  2.2325 -1.9192 -1.3765  1.4405  1.3821
[ CUDAFloatType{1,2,16} ]

T: out (after x + out) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.6878 -3.3532  3.7169  2.3623  1.7061  1.1380 -1.2902  1.2559  1.0681
 -0.4974 -2.6605  1.1876 -1.7264 -3.8698  2.5653  0.2180 -0.0327  3.6004

Columns 10 to 16 -1.4883  3.9305  0.7682  0.1999  1.5140  0.5359  0.3973
 -0.7946  4.3182  2.3247  0.4462  3.7508  1.0213 -0.3584
[ CUDAFloatType{1,2,16} ]

T: out (after dropout) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.6878 -3.3532  3.7169  2.3623  1.7061  1.1380 -1.2902  1.2559  1.0681
 -0.4974 -2.6605  1.1876 -1.7264 -3.8698  2.5653  0.2180 -0.0327  3.6004

Columns 10 to 16 -1.4883  3.9305  0.7682  0.1999  1.5140  0.5359  0.3973
 -0.7946  4.3182  2.3247  0.4462  3.7508  1.0213 -0.3584
[ CUDAFloatType{1,2,16} ]

out (after transformer layer) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.6878 -3.3532  3.7169  2.3623  1.7061  1.1380 -1.2902  1.2559  1.0681
 -0.4974 -2.6605  1.1876 -1.7264 -3.8698  2.5653  0.2180 -0.0327  3.6004

Columns 10 to 16 -1.4883  3.9305  0.7682  0.1999  1.5140  0.5359  0.3973
 -0.7946  4.3182  2.3247  0.4462  3.7508  1.0213 -0.3584
[ CUDAFloatType{1,2,16} ]

out (after out[:, 0]) -> [1, 16]
Columns 1 to 10-0.6878 -3.3532  3.7169  2.3623  1.7061  1.1380 -1.2902  1.2559  1.0681 -1.4883

Columns 11 to 16 3.9305  0.7682  0.1999  1.5140  0.5359  0.3973
[ CUDAFloatType{1,16} ]

out (after out layer 1) -> [1, 5]
 1.0616  3.1854 -1.9899  1.3622  0.9028
[ CUDAFloatType{1,5} ]

out (after squeeze()) -> [1, 5]
 1.0616  3.1854 -1.9899  1.3622  0.9028
[ CUDAFloatType{1,5} ]

final_result (softmax) -> [1, 5]
-2.4522 -0.3284 -5.5037 -2.1516 -2.6111
[ CUDAFloatType{1,5} ]

input -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -1.2655  0.6675  1.4087  1.4012  1.5775  1.2927  0.1235  0.0270  0.1235

Columns 10 to 16  0.3286  0.5206  0.7333  0.5520  0.5825  1.3092  1.7572
[ CUDAFloatType{1,1,16} ]

out (after input layer) -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -0.9648  1.2977  0.1897  2.2570 -0.1041 -0.8362 -0.8959 -0.6755  1.3184

Columns 10 to 16 -1.2927  1.3192 -0.4967 -0.7972 -1.2804 -1.8229  0.5914
[ CUDAFloatType{1,1,16} ]

cls_tokens -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
[ CUDAFloatType{1,1,16} ]

out (after class tokens) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -0.9648  1.2977  0.1897  2.2570 -0.1041 -0.8362 -0.8959 -0.6755  1.3184

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
 -1.2927  1.3192 -0.4967 -0.7972 -1.2804 -1.8229  0.5914
[ CUDAFloatType{1,2,16} ]

T: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -0.9648  1.2977  0.1897  2.2570 -0.1041 -0.8362 -0.8959 -0.6755  1.3184

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
 -1.2927  1.3192 -0.4967 -0.7972 -1.2804 -1.8229  0.5914
[ CUDAFloatType{1,2,16} ]

SA: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -0.9648  1.2977  0.1897  2.2570 -0.1041 -0.8362 -0.8959 -0.6755  1.3184

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
 -1.2927  1.3192 -0.4967 -0.7972 -1.2804 -1.8229  0.5914
[ CUDAFloatType{1,2,16} ]

SA: out (after qkv) -> [1, 2, 48]
(1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.3786  0.0597  0.5796 -0.2444  0.6899 -1.6707 -0.0273  0.1546  1.6197

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
  0.1332  2.0552 -0.6835  1.9241 -0.6180  1.3001 -2.1443  0.0641  1.2641

Columns 19 to 27 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438  0.0577  0.2429 -1.1539
 -2.6294 -2.1630  0.1321 -2.4623 -1.8308  2.2385  0.2427  0.4274  0.2277

Columns 28 to 36  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179 -0.4862  0.5505 -1.1303
  0.2977 -0.2983 -0.8812  0.1366 -0.1244  0.3350 -0.6044  0.4436 -0.9274

Columns 37 to 45 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444  0.1004 -1.4107  0.7586
 -0.9663  0.4926 -0.7915 -0.9452  0.2311  1.7297  0.9333  1.3227 -0.0394

Columns 46 to 48 -0.9349  1.4582 -0.2389
  2.1369 -2.6298 -2.6281
[ CUDAFloatType{1,2,48} ]

SA: out (after view) -> [1, 2, 2, 24]
(1,1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444

Columns 19 to 24 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
 Columns 1 to 9  0.3786  0.0597  0.5796 -0.2444  0.6899 -1.6707 -0.0273  0.1546  1.6197
  0.2427  0.4274  0.2277  0.2977 -0.2983 -0.8812  0.1366 -0.1244  0.3350

Columns 10 to 18  0.1332  2.0552 -0.6835  1.9241 -0.6180  1.3001 -2.1443  0.0641  1.2641
 -0.6044  0.4436 -0.9274 -0.9663  0.4926 -0.7915 -0.9452  0.2311  1.7297

Columns 19 to 24 -2.6294 -2.1630  0.1321 -2.4623 -1.8308  2.2385
  0.9333  1.3227 -0.0394  2.1369 -2.6298 -2.6281
[ CUDAFloatType{1,2,2,24} ]

SA: queries -> [1, 2, 2, 8]
(1,1,.,.) = 
  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043

(1,2,.,.) = 
  0.3786  0.0597  0.5796 -0.2444  0.6899 -1.6707 -0.0273  0.1546
  0.2427  0.4274  0.2277  0.2977 -0.2983 -0.8812  0.1366 -0.1244
[ CUDAFloatType{1,2,2,8} ]

SA: keys -> [1, 2, 2, 8]
(1,1,.,.) = 
 -1.5802  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811
  0.1179 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086

(1,2,.,.) = 
  1.6197  0.1332  2.0552 -0.6835  1.9241 -0.6180  1.3001 -2.1443
  0.3350 -0.6044  0.4436 -0.9274 -0.9663  0.4926 -0.7915 -0.9452
[ CUDAFloatType{1,2,2,8} ]

SA: values -> [1, 2, 2, 8]
(1,1,.,.) = 
 -0.8740  0.1034 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
 -0.1977 -0.1444  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
  0.0641  1.2641 -2.6294 -2.1630  0.1321 -2.4623 -1.8308  2.2385
  0.2311  1.7297  0.9333  1.3227 -0.0394  2.1369 -2.6298 -2.6281
[ CUDAFloatType{1,2,2,8} ]

SA: energy -> [1, 2, 2, 2]
(1,1,.,.) = 
 -10.1156  15.1028
  -1.8210   3.9721

(1,2,.,.) = 
 -9.8000 -9.0200
 -0.3593 -0.4884
[ CUDAFloatType{1,2,2,2} ]

SA: attention -> [1, 2, 2, 2]
(1,1,.,.) = 
  0.0018  0.9982
  0.1903  0.8097

(1,2,.,.) = 
  0.4514  0.5486
  0.5081  0.4919
[ CUDAFloatType{1,2,2,2} ]

SA: out (after einsum) -> [1, 2, 2, 8]
(1,1,.,.) = 
  0.0624  1.2620 -2.6260 -2.1611  0.1340 -2.4550 -1.8276  2.2350
  0.0376  0.8837  0.5573  0.0888  0.3208  0.7503 -0.7845 -1.5496

(1,2,.,.) = 
 -0.1144  1.0433 -2.2741 -1.9625  0.3228 -1.7044 -1.4979  1.8780
  0.0133  0.7775  0.5101 -0.0661  0.3660  0.5762 -0.5528 -1.4142
[ CUDAFloatType{1,2,2,8} ]

SA: out (after reshape) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.0624  1.2620 -2.6260 -2.1611  0.1340 -2.4550 -1.8276  2.2350  0.0376
 -0.1144  1.0433 -2.2741 -1.9625  0.3228 -1.7044 -1.4979  1.8780  0.0133

Columns 10 to 16  0.8837  0.5573  0.0888  0.3208  0.7503 -0.7845 -1.5496
  0.7775  0.5101 -0.0661  0.3660  0.5762 -0.5528 -1.4142
[ CUDAFloatType{1,2,16} ]

SA: out (after out()) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.4544  4.4583 -5.4272 -4.6951 -1.0076 -2.4809  0.7391  0.4960 -1.2910
  0.2219  3.6008 -4.6759 -3.8353 -1.2492 -2.1245  0.5674  0.4793 -0.9385

Columns 10 to 16  1.4987 -2.3859 -1.0819 -0.5482 -4.8340  1.0416 -0.0423
  1.3412 -1.8008 -0.8514 -0.4342 -3.8116  0.8270 -0.2547
[ CUDAFloatType{1,2,16} ]

SA: final_sum (before returning) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  2.1933  4.6811 -4.9052 -3.9773  0.7651 -2.0989 -0.0329  1.5635 -2.3352
 -0.7429  4.8984 -4.4862 -1.5783 -1.3533 -2.9607 -0.3285 -0.1962  0.3799

Columns 10 to 16  0.3415 -2.8012 -3.1785  0.2894 -5.2656  1.8855 -0.6625
  0.0485 -0.4816 -1.3481 -1.2315 -5.0920 -0.9958  0.3367
[ CUDAFloatType{1,2,16} ]

T: x (after self-attention) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  2.1933  4.6811 -4.9052 -3.9773  0.7651 -2.0989 -0.0329  1.5635 -2.3352
 -0.7429  4.8984 -4.4862 -1.5783 -1.3533 -2.9607 -0.3285 -0.1962  0.3799

Columns 10 to 16  0.3415 -2.8012 -3.1785  0.2894 -5.2656  1.8855 -0.6625
  0.0485 -0.4816 -1.3481 -1.2315 -5.0920 -0.9958  0.3367
[ CUDAFloatType{1,2,16} ]

T: out1 (after linear_1) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  2.1933  4.6811  0.0000  0.0000  0.7651  0.0000  0.0000  1.5635  0.0000
  0.0000  4.8984  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3799

Columns 10 to 16  0.3415  0.0000  0.0000  0.2894  0.0000  1.8855  0.0000
  0.0485  0.0000  0.0000  0.0000  0.0000  0.0000  0.3367
[ CUDAFloatType{1,2,16} ]

T: out2 (after linear_2) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  0.9008  1.6531 -0.7707  0.8899 -0.6329 -0.5306 -3.6832  1.5568 -6.3862
 -0.1881  1.3407 -0.5476  0.4441 -0.2245 -0.3543 -3.3010  0.7942 -6.5757

Columns 10 to 18 -0.2907 -0.9971 -1.0555  1.8983 -6.4601 -1.6193 -5.8739  1.1990 -1.0510
  0.2343 -0.3720  0.7927  1.7111 -6.1793  0.1157 -6.4364  1.1662 -0.8061

Columns 19 to 27  2.6311 -3.7789 -3.2484 -6.4998 -4.2577  1.2671  1.9030  0.0533  0.8313
  1.5801 -4.2564 -2.4496 -7.7598 -5.2627  1.5862  1.2622 -0.0587  0.5204

Columns 28 to 32 -1.4116  0.0183  1.3010  0.8526  1.0485
 -0.5789 -0.7340  0.9277 -0.2613 -0.6428
[ CUDAFloatType{1,2,32} ]

T: out4 (after linear_4) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  0.9008  1.6531  0.0000  0.8899  0.0000  0.0000  0.0000  1.5568  0.0000
  0.0000  1.3407  0.0000  0.4441  0.0000  0.0000  0.0000  0.7942  0.0000

Columns 10 to 18  0.0000  0.0000  0.0000  1.8983  0.0000  0.0000  0.0000  1.1990  0.0000
  0.2343  0.0000  0.7927  1.7111  0.0000  0.1157  0.0000  1.1662  0.0000

Columns 19 to 27  2.6311  0.0000  0.0000  0.0000  0.0000  1.2671  1.9030  0.0533  0.8313
  1.5801  0.0000  0.0000  0.0000  0.0000  1.5862  1.2622  0.0000  0.5204

Columns 28 to 32  0.0000  0.0183  1.3010  0.8526  1.0485
  0.0000  0.0000  0.9277  0.0000  0.0000
[ CUDAFloatType{1,2,32} ]

T: out5 (after linear_5) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -1.1062 -0.8270  0.6489 -1.7789  0.8784  0.1406 -1.1982  0.7371  1.5807
 -1.0584 -0.3962  0.7605 -1.2131  0.9658 -0.2750 -1.2065  0.5353  1.6745

Columns 10 to 16 -0.1410  1.9624  2.6484 -2.6644  1.7301  3.8110  1.0844
 -0.4986  1.7217  1.9539 -1.8542  1.3016  3.0815  1.1428
[ CUDAFloatType{1,2,16} ]

T: out (after x + out) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.0871  3.8541 -4.2564 -5.7562  1.6434 -1.9583 -1.2311  2.3005 -0.7546
 -1.8013  4.5022 -3.7258 -2.7914 -0.3875 -3.2356 -1.5350  0.3391  2.0544

Columns 10 to 16  0.2005 -0.8388 -0.5302 -2.3750 -3.5355  5.6965  0.4219
 -0.4501  1.2401  0.6059 -3.0857 -3.7905  2.0857  1.4794
[ CUDAFloatType{1,2,16} ]

T: out (after dropout) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.0871  3.8541 -4.2564 -5.7562  1.6434 -1.9583 -1.2311  2.3005 -0.7546
 -1.8013  4.5022 -3.7258 -2.7914 -0.3875 -3.2356 -1.5350  0.3391  2.0544

Columns 10 to 16  0.2005 -0.8388 -0.5302 -2.3750 -3.5355  5.6965  0.4219
 -0.4501  1.2401  0.6059 -3.0857 -3.7905  2.0857  1.4794
[ CUDAFloatType{1,2,16} ]

out (after transformer layer) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.0871  3.8541 -4.2564 -5.7562  1.6434 -1.9583 -1.2311  2.3005 -0.7546
 -1.8013  4.5022 -3.7258 -2.7914 -0.3875 -3.2356 -1.5350  0.3391  2.0544

Columns 10 to 16  0.2005 -0.8388 -0.5302 -2.3750 -3.5355  5.6965  0.4219
 -0.4501  1.2401  0.6059 -3.0857 -3.7905  2.0857  1.4794
[ CUDAFloatType{1,2,16} ]

out (after out[:, 0]) -> [1, 16]
Columns 1 to 10 1.0871  3.8541 -4.2564 -5.7562  1.6434 -1.9583 -1.2311  2.3005 -0.7546  0.2005

Columns 11 to 16-0.8388 -0.5302 -2.3750 -3.5355  5.6965  0.4219
[ CUDAFloatType{1,16} ]

out (after out layer 1) -> [1, 5]
 2.0815  2.0820  3.3220 -3.6617 -4.4647
[ CUDAFloatType{1,5} ]

out (after squeeze()) -> [1, 5]
 2.0815  2.0820  3.3220 -3.6617 -4.4647
[ CUDAFloatType{1,5} ]

final_result (softmax) -> [1, 5]
-1.6979 -1.6974 -0.4574 -7.4411 -8.2441
[ CUDAFloatType{1,5} ]

input -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -1.0651  0.6823  2.1739  2.2341  2.0506  2.3519 -0.1329  0.2283 -0.1329

Columns 10 to 16  0.9067  1.1108  1.6127  0.9117  1.3958  1.8126  0.9730
[ CUDAFloatType{1,1,16} ]

out (after input layer) -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -0.9100  1.7331  0.6217  3.3921 -0.6216 -1.3022 -0.3606 -1.4191  0.6208

Columns 10 to 16 -2.1611  2.3257 -0.1600 -2.0714 -1.8822 -2.8747  1.0543
[ CUDAFloatType{1,1,16} ]

cls_tokens -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
[ CUDAFloatType{1,1,16} ]

out (after class tokens) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -0.9100  1.7331  0.6217  3.3921 -0.6216 -1.3022 -0.3606 -1.4191  0.6208

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
 -2.1611  2.3257 -0.1600 -2.0714 -1.8822 -2.8747  1.0543
[ CUDAFloatType{1,2,16} ]

T: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -0.9100  1.7331  0.6217  3.3921 -0.6216 -1.3022 -0.3606 -1.4191  0.6208

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
 -2.1611  2.3257 -0.1600 -2.0714 -1.8822 -2.8747  1.0543
[ CUDAFloatType{1,2,16} ]

SA: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -0.9100  1.7331  0.6217  3.3921 -0.6216 -1.3022 -0.3606 -1.4191  0.6208

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
 -2.1611  2.3257 -0.1600 -2.0714 -1.8822 -2.8747  1.0543
[ CUDAFloatType{1,2,16} ]

SA: out (after qkv) -> [1, 2, 48]
(1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.0046  0.0435  0.3703 -0.1476  0.3484 -1.9395  0.3754  0.1206  2.9795

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
  0.5286  3.4573 -1.8195  3.9622 -0.8513  2.3604 -3.5891  1.0513  1.9608

Columns 19 to 27 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438  0.0577  0.2429 -1.1539
 -4.6948 -1.9257 -0.1708 -3.8652 -2.1803  2.2529 -0.1739  0.7428  0.3595

Columns 28 to 36  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179 -0.4862  0.5505 -1.1303
 -0.3224 -1.1258 -0.9595  0.3533 -0.6196  0.1829 -1.1242  1.1475 -2.2252

Columns 37 to 45 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444  0.1004 -1.4107  0.7586
 -1.3413  0.5789 -1.3680 -1.7798 -0.7491  2.6814  0.7222  2.5348  0.2003

Columns 46 to 48 -0.9349  1.4582 -0.2389
  3.4959 -4.2808 -3.7894
[ CUDAFloatType{1,2,48} ]

SA: out (after view) -> [1, 2, 2, 24]
(1,1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444

Columns 19 to 24 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
 Columns 1 to 9  0.0046  0.0435  0.3703 -0.1476  0.3484 -1.9395  0.3754  0.1206  2.9795
 -0.1739  0.7428  0.3595 -0.3224 -1.1258 -0.9595  0.3533 -0.6196  0.1829

Columns 10 to 18  0.5286  3.4573 -1.8195  3.9622 -0.8513  2.3604 -3.5891  1.0513  1.9608
 -1.1242  1.1475 -2.2252 -1.3413  0.5789 -1.3680 -1.7798 -0.7491  2.6814

Columns 19 to 24 -4.6948 -1.9257 -0.1708 -3.8652 -2.1803  2.2529
  0.7222  2.5348  0.2003  3.4959 -4.2808 -3.7894
[ CUDAFloatType{1,2,2,24} ]

SA: queries -> [1, 2, 2, 8]
(1,1,.,.) = 
  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043

(1,2,.,.) = 
  0.0046  0.0435  0.3703 -0.1476  0.3484 -1.9395  0.3754  0.1206
 -0.1739  0.7428  0.3595 -0.3224 -1.1258 -0.9595  0.3533 -0.6196
[ CUDAFloatType{1,2,2,8} ]

SA: keys -> [1, 2, 2, 8]
(1,1,.,.) = 
 -1.5802  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811
  0.1179 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086

(1,2,.,.) = 
  2.9795  0.5286  3.4573 -1.8195  3.9622 -0.8513  2.3604 -3.5891
  0.1829 -1.1242  1.1475 -2.2252 -1.3413  0.5789 -1.3680 -1.7798
[ CUDAFloatType{1,2,2,8} ]

SA: values -> [1, 2, 2, 8]
(1,1,.,.) = 
 -0.8740  0.1034 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
 -0.1977 -0.1444  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
  1.0513  1.9608 -4.6948 -1.9257 -0.1708 -3.8652 -2.1803  2.2529
 -0.7491  2.6814  0.7222  2.5348  0.2003  3.4959 -4.2808 -3.7894
[ CUDAFloatType{1,2,2,8} ]

SA: energy -> [1, 2, 2, 2]
(1,1,.,.) = 
 -10.1156  28.9064
  -0.8901   5.0698

(1,2,.,.) = 
 -9.8000 -17.5504
  1.4407  1.8371
[ CUDAFloatType{1,2,2,2} ]

SA: attention -> [1, 2, 2, 2]
(1,1,.,.) = 
  0.0001  0.9999
  0.1839  0.8161

(1,2,.,.) = 
  0.8741  0.1259
  0.4752  0.5248
[ CUDAFloatType{1,2,2,2} ]

SA: out (after einsum) -> [1, 2, 2, 8]
(1,1,.,.) = 
  1.0512  1.9607 -4.6945 -1.9257 -0.1708 -3.8649 -2.1801  2.2528
 -0.2671  0.2114  0.1787 -0.9139  0.6883 -0.3770  0.7356 -0.6860

(1,2,.,.) = 
  0.6972  1.6192 -3.9715 -1.7755  0.0692 -2.8746 -1.7942  1.9018
 -0.4870  1.3385  0.4267  0.6597  0.4656  1.3902 -1.5534 -2.1020
[ CUDAFloatType{1,2,2,8} ]

SA: out (after reshape) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.0512  1.9607 -4.6945 -1.9257 -0.1708 -3.8649 -2.1801  2.2528 -0.2671
  0.6972  1.6192 -3.9715 -1.7755  0.0692 -2.8746 -1.7942  1.9018 -0.4870

Columns 10 to 16  0.2114  0.1787 -0.9139  0.6883 -0.3770  0.7356 -0.6860
  1.3385  0.4267  0.6597  0.4656  1.3902 -1.5534 -2.1020
[ CUDAFloatType{1,2,16} ]

SA: out (after out()) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.7117  3.2236 -5.4764 -5.0172 -0.8982 -2.3515  2.7430 -0.1281 -1.4249
  0.4610  6.0412 -6.0465 -5.7957  0.0743 -3.0525  0.9243  1.6192 -3.1792

Columns 10 to 16  0.5411 -2.9565 -1.6264  0.0490 -6.7133 -0.1883  0.2318
  2.1538 -3.0743 -0.9173 -0.0261 -6.0464  1.2574  0.0160
[ CUDAFloatType{1,2,16} ]

SA: final_sum (before returning) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.0272  3.4464 -4.9544 -4.2994  0.8744 -1.9695  1.9710  0.9394 -2.4692
 -0.4490  7.7743 -5.4248 -2.4035 -0.5473 -4.3547  0.5637  0.2002 -2.5584

Columns 10 to 16 -0.6162 -3.3719 -3.7230  0.8865 -7.1449  0.6556 -0.3884
 -0.0073 -0.7486 -1.0773 -2.0975 -7.9287 -1.6173  1.0703
[ CUDAFloatType{1,2,16} ]

T: x (after self-attention) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.0272  3.4464 -4.9544 -4.2994  0.8744 -1.9695  1.9710  0.9394 -2.4692
 -0.4490  7.7743 -5.4248 -2.4035 -0.5473 -4.3547  0.5637  0.2002 -2.5584

Columns 10 to 16 -0.6162 -3.3719 -3.7230  0.8865 -7.1449  0.6556 -0.3884
 -0.0073 -0.7486 -1.0773 -2.0975 -7.9287 -1.6173  1.0703
[ CUDAFloatType{1,2,16} ]

T: out1 (after linear_1) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.0272  3.4464  0.0000  0.0000  0.8744  0.0000  1.9710  0.9394  0.0000
  0.0000  7.7743  0.0000  0.0000  0.0000  0.0000  0.5637  0.2002  0.0000

Columns 10 to 16  0.0000  0.0000  0.0000  0.8865  0.0000  0.6556  0.0000
  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  1.0703
[ CUDAFloatType{1,2,16} ]

T: out2 (after linear_2) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  1.0513  0.9231 -0.0862  1.7747  0.2009 -0.2968 -2.2129  1.1078 -4.3583
 -0.7258  1.9582 -0.8278  0.5866 -0.7294 -1.2302 -4.7487  1.2290 -10.0527

Columns 10 to 18  0.1964 -1.2608 -0.2152  1.6433 -4.3433 -1.1458 -3.9132  0.9093 -0.1878
  0.2309 -0.8614  1.8037  2.5523 -9.7460 -0.1587 -9.5946  1.7346 -0.8941

Columns 19 to 27  1.5533 -2.1829 -1.4578 -4.2618 -3.2010  0.3205  0.9998 -0.2872  0.6451
  2.3107 -6.5494 -3.8221 -11.9659 -8.5370  2.3174  2.1839 -0.3480  0.8903

Columns 28 to 32 -1.1665  0.5505  0.7950  0.6444  0.0131
 -0.8299 -1.2259  1.6330 -0.2886 -1.2358
[ CUDAFloatType{1,2,32} ]

T: out4 (after linear_4) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  1.0513  0.9231  0.0000  1.7747  0.2009  0.0000  0.0000  1.1078  0.0000
  0.0000  1.9582  0.0000  0.5866  0.0000  0.0000  0.0000  1.2290  0.0000

Columns 10 to 18  0.1964  0.0000  0.0000  1.6433  0.0000  0.0000  0.0000  0.9093  0.0000
  0.2309  0.0000  1.8037  2.5523  0.0000  0.0000  0.0000  1.7346  0.0000

Columns 19 to 27  1.5533  0.0000  0.0000  0.0000  0.0000  0.3205  0.9998  0.0000  0.6451
  2.3107  0.0000  0.0000  0.0000  0.0000  2.3174  2.1839  0.0000  0.8903

Columns 28 to 32  0.0000  0.5505  0.7950  0.6444  0.0131
  0.0000  0.0000  1.6330  0.0000  0.0000
[ CUDAFloatType{1,2,32} ]

T: out5 (after linear_5) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.5423 -0.0639  0.1758 -1.0401 -0.4929  0.6314 -0.2744  0.8321  0.0721
 -2.0834 -1.1320  1.6411 -1.1173  1.8317 -0.8157 -2.2340  0.5261  2.9178

Columns 10 to 16  0.9912  0.2910  1.2964 -2.2488  0.8751  1.7283 -0.0082
 -1.0938  2.9528  3.5904 -2.2370  2.2302  4.9293  2.0144
[ CUDAFloatType{1,2,16} ]

T: out (after x + out) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.4848  3.3825 -4.7786 -5.3395  0.3815 -1.3381  1.6967  1.7715 -2.3970
 -2.5324  6.6422 -3.7837 -3.5208  1.2844 -5.1704 -1.6703  0.7262  0.3594

Columns 10 to 16  0.3751 -3.0809 -2.4266 -1.3623 -6.2699  2.3838 -0.3966
 -1.1010  2.2042  2.5131 -4.3346 -5.6984  3.3120  3.0847
[ CUDAFloatType{1,2,16} ]

T: out (after dropout) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.4848  3.3825 -4.7786 -5.3395  0.3815 -1.3381  1.6967  1.7715 -2.3970
 -2.5324  6.6422 -3.7837 -3.5208  1.2844 -5.1704 -1.6703  0.7262  0.3594

Columns 10 to 16  0.3751 -3.0809 -2.4266 -1.3623 -6.2699  2.3838 -0.3966
 -1.1010  2.2042  2.5131 -4.3346 -5.6984  3.3120  3.0847
[ CUDAFloatType{1,2,16} ]

out (after transformer layer) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.4848  3.3825 -4.7786 -5.3395  0.3815 -1.3381  1.6967  1.7715 -2.3970
 -2.5324  6.6422 -3.7837 -3.5208  1.2844 -5.1704 -1.6703  0.7262  0.3594

Columns 10 to 16  0.3751 -3.0809 -2.4266 -1.3623 -6.2699  2.3838 -0.3966
 -1.1010  2.2042  2.5131 -4.3346 -5.6984  3.3120  3.0847
[ CUDAFloatType{1,2,16} ]

out (after out[:, 0]) -> [1, 16]
Columns 1 to 10 0.4848  3.3825 -4.7786 -5.3395  0.3815 -1.3381  1.6967  1.7715 -2.3970  0.3751

Columns 11 to 16-3.0809 -2.4266 -1.3623 -6.2699  2.3838 -0.3966
[ CUDAFloatType{1,16} ]

out (after out layer 1) -> [1, 5]
-1.3134 -1.6190  4.6123 -1.8271 -3.0747
[ CUDAFloatType{1,5} ]

out (after squeeze()) -> [1, 5]
-1.3134 -1.6190  4.6123 -1.8271 -3.0747
[ CUDAFloatType{1,5} ]

final_result (softmax) -> [1, 5]
-5.9324 -6.2380 -0.0067 -6.4461 -7.6937
[ CUDAFloatType{1,5} ]

input -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -1.5206  0.8772  2.4240  2.7692  1.9947  1.7806 -0.3579 -0.3051 -0.3579

Columns 10 to 16  0.5240  1.0552  1.1237  0.4233  0.3683  1.7584  1.5265
[ CUDAFloatType{1,1,16} ]

out (after input layer) -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9 -1.0585  1.6233  0.6845  3.7168 -0.6175 -1.4028 -1.2809 -1.6052  1.5951

Columns 10 to 16 -2.3327  2.6104  0.2920 -2.1740 -2.1682 -2.6481  0.7582
[ CUDAFloatType{1,1,16} ]

cls_tokens -> [1, 1, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
[ CUDAFloatType{1,1,16} ]

out (after class tokens) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -1.0585  1.6233  0.6845  3.7168 -0.6175 -1.4028 -1.2809 -1.6052  1.5951

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
 -2.3327  2.6104  0.2920 -2.1740 -2.1682 -2.6481  0.7582
[ CUDAFloatType{1,2,16} ]

T: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -1.0585  1.6233  0.6845  3.7168 -0.6175 -1.4028 -1.2809 -1.6052  1.5951

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
 -2.3327  2.6104  0.2920 -2.1740 -2.1682 -2.6481  0.7582
[ CUDAFloatType{1,2,16} ]

SA: input -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.7389  0.2228  0.5220  0.7178  1.7726  0.3820 -0.7720  1.0675 -1.0442
 -1.0585  1.6233  0.6845  3.7168 -0.6175 -1.4028 -1.2809 -1.6052  1.5951

Columns 10 to 16 -1.1573 -0.4153 -2.0966  0.8376 -0.4316  0.8439 -0.6202
 -2.3327  2.6104  0.2920 -2.1740 -2.1682 -2.6481  0.7582
[ CUDAFloatType{1,2,16} ]

SA: out (after qkv) -> [1, 2, 48]
(1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.0164  0.4844  0.3939 -0.2260  0.1769 -2.2735  0.7081  0.4257  3.2096

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
  0.6028  3.6101 -2.0372  3.9737 -1.1905  2.6706 -4.1881  1.2817  1.9794

Columns 19 to 27 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438  0.0577  0.2429 -1.1539
 -4.2908 -2.7873 -0.6183 -4.1678 -2.5554  2.7088  0.1397  0.9029  0.3141

Columns 28 to 36  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179 -0.4862  0.5505 -1.1303
  0.1248 -0.7144 -1.4118  0.4349 -0.5825  0.1104 -0.7552  0.8237 -1.6010

Columns 37 to 45 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444  0.1004 -1.4107  0.7586
 -0.9341  0.3851 -1.3610 -1.2708 -0.9444  3.6930  0.8897  2.5123 -0.5204

Columns 46 to 48 -0.9349  1.4582 -0.2389
  4.2239 -3.9136 -5.2219
[ CUDAFloatType{1,2,48} ]

SA: out (after view) -> [1, 2, 2, 24]
(1,1,.,.) = 
 Columns 1 to 9  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534 -1.5802
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043  0.1179

Columns 10 to 18  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811 -0.8740  0.1034
 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086 -0.1977 -0.1444

Columns 19 to 24 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
 Columns 1 to 9  0.0164  0.4844  0.3939 -0.2260  0.1769 -2.2735  0.7081  0.4257  3.2096
  0.1397  0.9029  0.3141  0.1248 -0.7144 -1.4118  0.4349 -0.5825  0.1104

Columns 10 to 18  0.6028  3.6101 -2.0372  3.9737 -1.1905  2.6706 -4.1881  1.2817  1.9794
 -0.7552  0.8237 -1.6010 -0.9341  0.3851 -1.3610 -1.2708 -0.9444  3.6930

Columns 19 to 24 -4.2908 -2.7873 -0.6183 -4.1678 -2.5554  2.7088
  0.8897  2.5123 -0.5204  4.2239 -3.9136 -5.2219
[ CUDAFloatType{1,2,2,24} ]

SA: queries -> [1, 2, 2, 8]
(1,1,.,.) = 
  1.8141  0.1064  1.3582 -1.2318  2.9613  0.0266  0.2789 -1.1534
  0.0577  0.2429 -1.1539  3.1229  2.7158 -0.0926 -0.1509  3.1043

(1,2,.,.) = 
  0.0164  0.4844  0.3939 -0.2260  0.1769 -2.2735  0.7081  0.4257
  0.1397  0.9029  0.3141  0.1248 -0.7144 -1.4118  0.4349 -0.5825
[ CUDAFloatType{1,2,2,8} ]

SA: keys -> [1, 2, 2, 8]
(1,1,.,.) = 
 -1.5802  0.1260 -1.0958  0.9700 -0.9456 -0.0374 -0.6638  1.3811
  0.1179 -0.4862  0.5505 -1.1303 -1.2402  0.4012 -0.5385 -0.7086

(1,2,.,.) = 
  3.2096  0.6028  3.6101 -2.0372  3.9737 -1.1905  2.6706 -4.1881
  0.1104 -0.7552  0.8237 -1.6010 -0.9341  0.3851 -1.3610 -1.2708
[ CUDAFloatType{1,2,2,8} ]

SA: values -> [1, 2, 2, 8]
(1,1,.,.) = 
 -0.8740  0.1034 -0.7622 -1.1091  1.1345  1.5210 -0.0810  0.3438
 -0.1977 -0.1444  0.1004 -1.4107  0.7586 -0.9349  1.4582 -0.2389

(1,2,.,.) = 
  1.2817  1.9794 -4.2908 -2.7873 -0.6183 -4.1678 -2.5554  2.7088
 -0.9444  3.6930  0.8897  2.5123 -0.5204  4.2239 -3.9136 -5.2219
[ CUDAFloatType{1,2,2,8} ]

SA: energy -> [1, 2, 2, 2]
(1,1,.,.) = 
 -10.1156  30.6099
  -0.5799   5.7446

(1,2,.,.) = 
 -9.8000 -12.4393
  0.1074 -0.3356
[ CUDAFloatType{1,2,2,2} ]

SA: attention -> [1, 2, 2, 2]
(1,1,.,.) = 
  0.0000  1.0000
  0.1706  0.8294

(1,2,.,.) = 
  0.6592  0.3408
  0.5277  0.4723
[ CUDAFloatType{1,2,2,2} ]

SA: out (after einsum) -> [1, 2, 2, 8]
(1,1,.,.) = 
  1.2816  1.9793 -4.2907 -2.7872 -0.6182 -4.1676 -2.5553  2.7088
 -0.4521  1.1633  0.3694 -0.0738  0.3227  0.8231 -0.3724 -1.9370

(1,2,.,.) = 
  0.9139  1.6593 -3.6887 -2.5009 -0.3192 -3.1971 -2.1331  2.3053
 -0.5504  1.6682  0.4732  0.4423  0.1545  1.5018 -1.0792 -2.5926
[ CUDAFloatType{1,2,2,8} ]

SA: out (after reshape) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  1.2816  1.9793 -4.2907 -2.7872 -0.6182 -4.1676 -2.5553  2.7088 -0.4521
  0.9139  1.6593 -3.6887 -2.5009 -0.3192 -3.1971 -2.1331  2.3053 -0.5504

Columns 10 to 16  1.1633  0.3694 -0.0738  0.3227  0.8231 -0.3724 -1.9370
  1.6682  0.4732  0.4423  0.1545  1.5018 -1.0792 -2.5926
[ CUDAFloatType{1,2,16} ]

SA: out (after out()) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  0.6173  6.1559 -6.8196 -6.6093 -0.5955 -3.1904  2.4986  0.9612 -2.9826
  1.0095  6.8597 -6.4244 -6.3205 -0.5256 -3.1779  1.6658  1.8669 -3.5978

Columns 10 to 16  2.3990 -3.4507 -1.4827 -0.3095 -7.2597  0.3822  0.5425
  3.1004 -2.9796 -0.9259 -0.2619 -6.0682  0.8035  0.3062
[ CUDAFloatType{1,2,16} ]

SA: final_sum (before returning) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  2.3562  6.3787 -6.2976 -5.8915  1.1772 -2.8084  1.7266  2.0287 -4.0269
 -0.0490  8.4830 -5.7399 -2.6038 -1.1431 -4.5807  0.3848  0.2618 -2.0027

Columns 10 to 16  1.2417 -3.8661 -3.5793  0.5280 -7.6913  1.2260 -0.0777
  0.7676 -0.3692 -0.6339 -2.4359 -8.2364 -1.8446  1.0644
[ CUDAFloatType{1,2,16} ]

T: x (after self-attention) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  2.3562  6.3787 -6.2976 -5.8915  1.1772 -2.8084  1.7266  2.0287 -4.0269
 -0.0490  8.4830 -5.7399 -2.6038 -1.1431 -4.5807  0.3848  0.2618 -2.0027

Columns 10 to 16  1.2417 -3.8661 -3.5793  0.5280 -7.6913  1.2260 -0.0777
  0.7676 -0.3692 -0.6339 -2.4359 -8.2364 -1.8446  1.0644
[ CUDAFloatType{1,2,16} ]

T: out1 (after linear_1) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  2.3562  6.3787  0.0000  0.0000  1.1772  0.0000  1.7266  2.0287  0.0000
  0.0000  8.4830  0.0000  0.0000  0.0000  0.0000  0.3848  0.2618  0.0000

Columns 10 to 16  1.2417  0.0000  0.0000  0.5280  0.0000  1.2260  0.0000
  0.7676  0.0000  0.0000  0.0000  0.0000  0.0000  1.0644
[ CUDAFloatType{1,2,16} ]

T: out2 (after linear_2) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  0.9338  2.8482  0.8249  1.8071  0.7676 -1.7760 -5.4311  2.0075 -9.3936
 -1.0705  2.6901  0.1041  0.3710 -0.0781 -1.6917 -5.8855  1.2822 -11.7738

Columns 10 to 18  1.0313 -1.7142 -0.2464  2.7848 -8.6638 -2.7693 -8.0842  2.9544 -0.7301
  0.8746 -0.8483  2.0462  2.6477 -11.0354 -0.3978 -10.8788  2.5843 -0.8535

Columns 19 to 27  2.9936 -6.5837 -3.7848 -9.1271 -5.9638  1.6544  2.8964  0.4838  1.1073
  2.4475 -8.6068 -4.3215 -13.4790 -9.1483  2.9151  2.9011  0.3571  0.9683

Columns 28 to 32 -2.0851  0.7232  0.8709  0.3768 -1.0014
 -0.9982 -1.1731  1.2701 -0.8071 -2.1398
[ CUDAFloatType{1,2,32} ]

T: out4 (after linear_4) -> [1, 2, 32]
(1,.,.) = 
 Columns 1 to 9  0.9338  2.8482  0.8249  1.8071  0.7676  0.0000  0.0000  2.0075  0.0000
  0.0000  2.6901  0.1041  0.3710  0.0000  0.0000  0.0000  1.2822  0.0000

Columns 10 to 18  1.0313  0.0000  0.0000  2.7848  0.0000  0.0000  0.0000  2.9544  0.0000
  0.8746  0.0000  2.0462  2.6477  0.0000  0.0000  0.0000  2.5843  0.0000

Columns 19 to 27  2.9936  0.0000  0.0000  0.0000  0.0000  1.6544  2.8964  0.4838  1.1073
  2.4475  0.0000  0.0000  0.0000  0.0000  2.9151  2.9011  0.3571  0.9683

Columns 28 to 32  0.0000  0.7232  0.8709  0.3768  0.0000
  0.0000  0.0000  1.2701  0.0000  0.0000
[ CUDAFloatType{1,2,32} ]

T: out5 (after linear_5) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9 -0.0483  0.1502 -0.4593 -4.0256 -0.4420  0.5878 -1.7366  0.9818  2.5287
 -1.8923 -1.1220  1.3957 -1.8368  1.9488 -1.0066 -2.3888  0.5778  3.8687

Columns 10 to 16  0.4675  2.3182  2.5456 -4.5727  2.3524  5.4159  0.6423
 -1.4776  3.6788  3.6853 -2.8663  2.8460  5.8935  2.1910
[ CUDAFloatType{1,2,16} ]

T: out (after x + out) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  2.3079  6.5290 -6.7569 -9.9170  0.7352 -2.2205 -0.0100  3.0105 -1.4982
 -1.9413  7.3610 -4.3442 -4.4406  0.8057 -5.5873 -2.0040  0.8396  1.8660

Columns 10 to 16  1.7092 -1.5478 -1.0337 -4.0447 -5.3389  6.6420  0.5646
 -0.7100  3.3096  3.0514 -5.3022 -5.3904  4.0489  3.2554
[ CUDAFloatType{1,2,16} ]

T: out (after dropout) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  2.3079  6.5290 -6.7569 -9.9170  0.7352 -2.2205 -0.0100  3.0105 -1.4982
 -1.9413  7.3610 -4.3442 -4.4406  0.8057 -5.5873 -2.0040  0.8396  1.8660

Columns 10 to 16  1.7092 -1.5478 -1.0337 -4.0447 -5.3389  6.6420  0.5646
 -0.7100  3.3096  3.0514 -5.3022 -5.3904  4.0489  3.2554
[ CUDAFloatType{1,2,16} ]

out (after transformer layer) -> [1, 2, 16]
(1,.,.) = 
 Columns 1 to 9  2.3079  6.5290 -6.7569 -9.9170  0.7352 -2.2205 -0.0100  3.0105 -1.4982
 -1.9413  7.3610 -4.3442 -4.4406  0.8057 -5.5873 -2.0040  0.8396  1.8660

Columns 10 to 16  1.7092 -1.5478 -1.0337 -4.0447 -5.3389  6.6420  0.5646
 -0.7100  3.3096  3.0514 -5.3022 -5.3904  4.0489  3.2554
[ CUDAFloatType{1,2,16} ]

out (after out[:, 0]) -> [1, 16]
Columns 1 to 10 2.3079  6.5290 -6.7569 -9.9170  0.7352 -2.2205 -0.0100  3.0105 -1.4982  1.7092

Columns 11 to 16-1.5478 -1.0337 -4.0447 -5.3389  6.6420  0.5646
[ CUDAFloatType{1,16} ]

out (after out layer 1) -> [1, 5]
 1.7600  1.5623  6.4088 -5.4776 -7.0983
[ CUDAFloatType{1,5} ]

out (after squeeze()) -> [1, 5]
 1.7600  1.5623  6.4088 -5.4776 -7.0983
[ CUDAFloatType{1,5} ]

final_result (softmax) -> [1, 5]
-4.6661 -4.8638 -0.0173 -11.9037 -13.5244
[ CUDAFloatType{1,5} ]
Predictions:
[-0.9349128007888794, -0.9796414375305176, -3.7985024452209473, -2.2567129135131836, -2.255359411239624] [-2.452205181121826, -0.32840824127197266, -5.503724098205566, -2.1515917778015137, -2.6110546588897705] [-1.6978509426116943, -1.6973888874053955, -0.4574224650859833, -7.441123008728027, -8.244084358215332] [-5.932358264923096, -6.237990856170654, -0.006670469883829355, -6.446122169494629, -7.693709373474121]

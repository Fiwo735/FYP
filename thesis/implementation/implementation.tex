\chapter{Implementation}\label{implementation}
As depicted in the figure \ref{fig:gantt-chart}, part of the project plan from \autoref{project-plan} has already been implemented as of the time of publishing this report. This was done thanks to the smaller workload of the Autumn term in comparison to the Spring term as well as the significant effort over the Winter break. This 'head start' is hoped to allow for a deeper state space exploration and a more refined final architecture and in case of faster than expected working pace, further extensions related to the \textit{hls4ml} library and automatic optimizations will also be considered. The accomplishments so far can be categorized into four domains covered in the following sections.

\section{Adaptation of the PyTorch ConstituentNet architecture}
Thanks to the existing code base with an implementation, it was easier to understand the smaller details that were not fully explained in the original paper \cite{3-yuan2021constituentnet:}. However, many aspects of the provided code served as proof-of-concept and are suspected to had been changed after the publishing, as a new model could not have had been trained, nor the provided one could have had been evaluated. Without the help of the original author, a severe investigation and fixing process were required to progress the software implementation into a usable state. Despite those difficulties, the time was well spent on finding potential optimization points for the later stage of the project. Moreover, frequent reporting hooks were added in between the existing network layers, which allows for generating an inner view of the calculations happening on the CPU that gives the opportunity for direct, step-by-step comparison with the HLS implementation. Ultimately, the code base has reached a state where it is convenient to train models with different parameters and evaluate them against the datasets.
  
\section{Parameter extraction tool with normalization embedding}
In order to generate files with weights and biases that are required for initializing the memory on an FPGA, a tool was developed that takes a PyTorch pre-trained model, extracts all the information, and splits them accordingly with the required format. What is more, layers responsible for normalization can be chosen to have their mean and variance calculation embedded into weights and biases to significantly reduce the processing required on an FPGA by omitting the division and square root operations. The mathematical derivation of this approach starts with the batch norm formula:
\[ y = \frac{x - E[x]}{\sqrt{Var[x] + \epsilon}} * \gamma + \beta \]
The expected value and variance are treated as learnable parameter of a dataset and are extracted after the training has been completed. Hence, the calculation becomes:
\[ y = x * \frac{\gamma}{\sqrt{Var + \epsilon}} + \beta - \frac{\gamma * E}{\sqrt{Var + \epsilon}} = x * W + b\]
The newly calculated values for \(W\) and \(b\) represent the updated weights and biases of the normalization layer, that can be then implemented in hardware in a much simpler way. Independently of the implementation in this work, a similar idea has been proposed and successfully used as an optimization in the past \cite{46-fan2018real-time}.
  
\section{Implementation of ConstituentNet in Vivado HLS}
An effort has been made to express the original version of ConstituentNet in HLS based off an empty skeleton code generated by \textit{hl4ml}. So far, the architecture, including the blocks responsible for the transformer and the self-attention calculations, have been designed and connected accordingly. Several layer types, namely the densely-connected, normalization and activation ones have already been successfully validated. A variant of the densely-connected layer used for matrix-matrix multiplication, along with a few smaller layers, are yet to be validated, at which point, the architecture would be ready for an evaluation against the PyTorch implementation.
  
\section{Research into the \textit{hls4ml} library and integration potential}
The current HLS implementation benefits from a number of existing layers included as part of the \textit{hls4ml} library. This has been done as a way to shorten the time needed for the initial HLS implementation that will serve as the baseline for further optimizations as well as to research the structure and methods used in the library to allow for a smoother integration into the codesign workflow once the initial objective is met.
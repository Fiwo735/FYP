\chapter{Evaluation Plan}

This section outlines the proposed evaluation plan for the project. The first objective of developing and optimizing a state-of-the-art neural network in hardware can be evaluated quantitatively, while integrating it into the \textit{hls4ml} library and making it easy for new users to use requires a more qualitative approach.

\section{Quantitative results}
The following describes the quantities that are planned to be measured:

\begin{outline}
  \1 Classification accuracy for each designed neural network on a validation dataset
  \1 Inference latency and throughput when running on the target platform
  \1 Hardware resource utilization (exact values for comparison with other platforms and percentage of available resources for understanding limitations):
    \2 Block RAM (BRAM)
    \2 Ultra RAM (URAM)
    \2 Digital Signal Processing units (DSP)
    \2 Flip-Flops (FF)
    \2 Look-Up Tables (LUT)
\end{outline}

In the early stages of the project, the above quantities will be measured from the results from simulation and synthesis reports. At a later stage, the best designs will be run on actual hardware platforms to validate them under real-life use cases. The platform planned for this part is an Intel Stratix V FPGA hosted in a Maxeler MPC-X dataflow node with 8 Maia dataflow engines and 48 GB of DRAM.

Apart from clear design improvements, it is predicted that most evaluated designs will offer trade-offs between classification accuracy, inference throughput and hardware utilization. It is not possible to find a design that is superior in every way, hence a \textbf{Pareto front} will play a key role in understanding the overall performance and selecting configuration with specific needs in mind.

\section{Qualitative results}
Qualitative

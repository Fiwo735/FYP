\chapter{Evaluation}\label{evaluation}
This chapter starts by evaluating the proposed neural network architectures on CPUs and GPUs to find a baseline inference latency, accuracy and AUC values. This information is then compared with the results obtained from simulating and synthesizing the models on reconfigurable hardware. The outcome of the design space exploration includes hardware resource utilization metrics as well as discussion about the Pareto front and applicability in high energy physics environments. Lastly, both the quantization-aware training and post-training quantization are evaluated quantitatively in terms of the trade-off between quality of results and bit-width reduction as well as qualitatively for their ease of adaptation to existing designs.
\indo{Correct the above}

As efficient hardware mapping is the motivation behind the proposed models, out of the constituent list representation datasets, only the one containing 30 most energetic jets is analyzed in this chapter due to the inherent complexity of transformer neural networks and the challenges involved in mapping bigger designs to FPGAs.

\section{Proposed Models' Performance}
The first objective of the project is to design neural network architectures capable of very fast and accurate classification. Firstly, the classification accuracies and ROC curves are analyzed. Then, the choice of a dataset for both models is discussed, followed by inference latency results and comparison to existing solutions.

\subsection{Classification Accuracy}
Table \ref{tab:classification-results} shows the evaluation results of the base and the two proposed architectures on the HLF and the constituent list datasets. Compared to the base one, the ultra-low latency model requires roughly 156 times fewer parameters and 2,875 times fewer FLOPS while achieving comparable classification results, suggesting that the base model has significantly too much learning capacity for that dataset. The second model also offers a notable parameters and FLOPS reduction of around 4 times. This matches the quadratic complexity of the self-attention layer given that the latent dimension is reduced from \(128\) to \(64\) and proves the importance of this factor. Along this, there is a slight improvement in accuracy and AUC thanks to a more careful selection of the design parameters.

\begin{table}[hpt!]
  \centering
  \caption{Comparison between classification accuracy, average ROC metrics, parameter count, and FLOPS between the baseline and the proposed architectures.}
  \label{tab:classification-results}
  \bgroup
  \def\arraystretch{1.2}
  \setlength\tabcolsep{2.5mm}
  \begin{tabular}{|c|c|c|c|c|c|}
  \hline
  \textbf{Architecture} & \textbf{Dataset} & \textbf{\begin{tabular}[c]{@{}c@{}}Classification\\ Accuracy (\%)\end{tabular}} & \textbf{AUC} & \textbf{Parameters} & \textbf{FLOPS} \\ \hline
  Base & \multirow{2}{*}{HLF} & 76.50 & 0.9429 & 399,901 & 102 M \\ \cline{1-1} \cline{3-6} 
  Ultra-Low Latency &  & 76.09 & 0.9396 & 2,605 & 583 k \\ \hline
  Base & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Constituents\\ (30)\end{tabular}} & 77.56 & 0.9473 & 405,643 & 1,676 M \\ \cline{1-1} \cline{3-6} 
  Accuracy-Focused &  & 77.81 & 0.9480 & 107,403 & 448 M \\ \hline
  \end{tabular}
  \egroup
  \end{table}

\subsection{Receiver Operating Characteristic Curves and their Areas}
Analyzing the ROC curves offers a more complex analysis of the trade-offs in classification results between the base and the proposes architecture.

\begin{figure}[!hpt]
  \centering
  \begin{tabular}{ccc}
      {\includegraphics[width=0.48\columnwidth]{../logs/ROC.png}} &
      {\includegraphics[width=0.48\columnwidth]{../logs/ROC.png}}
  \end{tabular}
  \caption{Comparison between ROC and AUC of the base (left) and ultra-low latency (right) models using the HLF dataset.}
  \label{fig:ROCs-HLF}
\end{figure}

Figure \ref{fig:ROCs-HLF} compares the base and the ultra-low latency models trained on the HLF dataset. The curves behave very similarly, with the ones associated with gluons and light quarks achieving notably lower true positive rates (TRPs) at lower false positive rates (FPRs), which means that both models have more troubles between distinguishing between these two jet categories.

\begin{figure}[!hpt]
  \centering
  \begin{tabular}{ccc}
      {\includegraphics[width=0.48\columnwidth]{../logs/ROC.png}} &
      {\includegraphics[width=0.48\columnwidth]{../logs/ROC.png}}
  \end{tabular}
  \caption{Comparison between ROC and AUC of the base (left) and accuracy-focused (right) models using the constituent list dataset.}
  \label{fig:ROCs-constituent}
\end{figure}

Figure \ref{fig:ROCs-constituent} shows an analogous comparison for the base and accuracy-focused models using the constituent list representation. TODO

\begin{table}[]
  \centering
  \caption{}
  \label{tab:AUCs}
  \begin{tabular}{|c|c|cc|}
  \hline
  \multirow{2}{*}{\textbf{Particle}} & \multirow{2}{*}{\textbf{AUC}} & \multicolumn{2}{c|}{\textbf{TPR @ FPR}} \\ \cline{3-4} 
   &  & \multicolumn{1}{c|}{\textbf{10 \%}} & \textbf{1 \%} \\ \hline
  Gluon &  & \multicolumn{1}{c|}{} &  \\ \hline
  Light quarks &  & \multicolumn{1}{c|}{} &  \\ \hline
  Top quark &  & \multicolumn{1}{c|}{} &  \\ \hline
  W boson &  & \multicolumn{1}{c|}{} &  \\ \hline
  Z boson &  & \multicolumn{1}{c|}{} &  \\ \hline
  \end{tabular}
\end{table}

Table \ref{tab:AUCs} provides a comprehensive view of the models' true positive rates at 10 \% and 1 \% false positive rates, comparing them to other state-of-the-art neural network architectures introduced in \cref{background}.

\subsection{CPU and GPU Latency}

\indo{Latency on CPUs and GPUs, extend table below with accuracy-focused latency results or just create a second one}
\indo{Comment on how little difference there is between all CPUs and GPUs}
\indo{|}
\indo{|}

The detailed specifications of the four machines used for measuring the inference time are listed below. All machines have CentOS 7.0 operating system, while the first listed machine, which is the GPUs host, uses CUDA version 11.5, with driver version 495.29.05.

\begin{itemize}
  \item Dual Intel Xeon Silver 4110 at 2.10GHz with 192 GB DDR4 RAM at 2666 MT/s,
  \item Dual Intel Xeon X5690 at 3.47GHz with 96 GB DDR3 RAM at 1333 MT/s,
  \item Intel Xeon E5-2620 v3 at 2.40GHz with 192 GB DDR4 RAM at 2133 MT/s,
  \item Dual Intel Xeon Gold 6154 CPU at 3.00GHz with 768 GB DDR4 RAM at 2666 MT/s,
\end{itemize}


\begin{table}[hpt!]
  \centering
  \caption{Comparison of ultra-low latency model's inference times, with batch size of 128}
  \label{tab:inference-times}
  \bgroup
  \def\arraystretch{1.2}
  \setlength\tabcolsep{3mm}
  \begin{tabular}{c|l|cc|}
  \cline{2-4}
  \multicolumn{1}{l|}{}                               & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Device}}}       & \multicolumn{2}{c|}{\textbf{Inference time}}                      \\ \cline{3-4} 
  \multicolumn{1}{l|}{}                               & \multicolumn{1}{c|}{}                                       & \multicolumn{1}{c|}{per batch (ms)}          & per sample ($\mu$s) \\ \hline
  \multicolumn{1}{|c|}{\multirow{4}{*}{\textbf{\begin{sideways}CPU\end{sideways}}}} & Intel Xeon Silver 4110 (Dual) & \multicolumn{1}{c|}{1.741 $\pm$ 0.027}       & 13.604 $\pm$ 0.207 \\ \cline{2-4} 
  \multicolumn{1}{|c|}{}                              & Intel Xeon X5690 (Dual)                                     & \multicolumn{1}{c|}{1.622 $\pm$ 0.026}       & 12.670 $\pm$ 0.206 \\ \cline{2-4} 
  \multicolumn{1}{|c|}{}                              & Intel Xeon E5-2620 v3                                       & \multicolumn{1}{c|}{1.325 $\pm$ 0.123}       & 10.350 $\pm$ 0.963 \\ \cline{2-4}
  \multicolumn{1}{|c|}{}                              & Intel Xeon Gold 6154 (Dual)                                 & \multicolumn{1}{c|}{1.167 $\pm$ 0.066}       & 9.112 $\pm$ 0.516  \\ \hline\hline
  \multicolumn{1}{|c|}{\multirow{3}{*}{\textbf{\begin{sideways}GPU\end{sideways}}}} & Nvidia GTX 1080 Ti            & \multicolumn{1}{c|}{1.166 $\pm$ 0.112}       & 9.111 $\pm$ 0.876  \\ \cline{2-4} 
  \multicolumn{1}{|c|}{}                              & Nvidia TITAN X                                              & \multicolumn{1}{c|}{1.154 $\pm$ 0.119}       & 9.017 $\pm$ 0.928  \\ \cline{2-4} 
  \multicolumn{1}{|c|}{}                              & Nvidia TITAN Xp                                             & \multicolumn{1}{c|}{1.062 $\pm$ 0.036}       & 8.296 $\pm$ 0.283  \\ \cline{2-4} 
  \hline
  \end{tabular}
  \egroup
\end{table}



\subsection{Comparison with Existing Solutions}

\begin{table}[!hpt]
  \centering
  \caption{Summary of networks' inference time, accuracy, Floating-Point Operations Per Second and parameter number for optimal batch sizes, with best values in bold.}
  \label{tab:all-networks-comparison}
  \bgroup
  \def\arraystretch{1.2}
  \setlength\tabcolsep{1.5mm}
  \begin{tabular}{|c|c|c|c|c|}
  \hline
  \textbf{\begin{tabular}[c]{@{}c@{}}Neural network\\ \end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Inference per\\ batch (ms)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Accuracy /\\ aver. AUC\end{tabular}} & \textbf{FLOPS} & \textbf{Parameters} \\ \hline
  DNN \cite{9-newman2019jedi-net:} & \textbf{1.0 $\pm$ 0.2} & 0.760 / 0.941 & \textbf{27 k} & 14,725 \\ \hline
  CNN \cite{9-newman2019jedi-net:} & 57.1 $\pm$ 0.5 & 0.740 / 0.911 & 400 k & 205,525 \\ \hline
  GRU \cite{9-newman2019jedi-net:} & 23.2 $\pm$ 0.6 & 0.750 / 0.912 & 46 k & 15,575 \\ \hline
  JEDI-net \cite{9-newman2019jedi-net:} & 121.2 $\pm$ 0.4 & TODO / 0.959 & 116 M & 33,625 \\ \hline
  JEDI-net with $\sum O$ \cite{9-newman2019jedi-net:}  & 402.0 $\pm$ 1.0 & TODO / 0.957 & 458 M & 8,767 \\ \hline
  ConstituentNet-Base \cite{3-yuan2021constituentnet:} & $\sim$773.0 & 0.818 / \textbf{0.966} & 1,553 M & 289,000 \\ \hline
  ConstituentNet-Tiny \cite{3-yuan2021constituentnet:} & $\sim$17.0 & 0.805 / 0.960 & 13 M  & \textbf{8,533} \\ \hline
  \end{tabular}
  \egroup
\end{table}

% Ultra-low latency
% Test accuracy: 76.09% in 2.76 s
% -------------------------------------------------------
% Particle        AUC        TPR @ FPR=10%   TPR @ FPR=1%
% -------------------------------------------------------
% Gluon:        0.9372          0.8057          0.3928  
% Light quark:  0.9000          0.6813          0.1618  
% W boson:      0.9610          0.9079          0.6207  
% Z boson:      0.9525          0.8390          0.6277  
% Top quark:    0.9474          0.8304          0.7064  
% -------------------------------------------------------
% Average:      0.9396          0.8129          0.5019  
% -------------------------------------------------------

% Accuracy-Focused
% Test accuracy: 77.35% in 9.74 s
% -------------------------------------------------------
% Particle        AUC        TPR @ FPR=10%   TPR @ FPR=1%
% -------------------------------------------------------
% Gluon:        0.9280          0.7765          0.3242  
% Light quark:  0.9201          0.7729          0.2788  
% W boson:      0.9622          0.8990          0.5632  
% Z boson:      0.9571          0.8768          0.6704  
% Top quark:    0.9620          0.9094          0.5553  
% -------------------------------------------------------
% Average:      0.9459          0.8469          0.4784  
% -------------------------------------------------------



\section{Hardware Acceleration}
\indo{Small introduction}
Thanks to its high-performance, XCU250 (variant figd2104-2L-e) was chosen as the target FPGA platform.
\indo{Brief info about XCU250}

\indo{compare with the dnn built using hls4ml}



\subsection{Ultra-Low Latency Model}
\indo{Discuss hardware resources and latency}
\indo{also mention interval of 1}
\indo{|}
\indo{|}
\indo{|}

\indo{Small table with cycles, latency, clock frequency}
\indo{|}
\indo{|}

\begin{table}[hpt!]
  \centering
  \caption{FPGA resources utilization}
  \label{tab:utilization}
  \bgroup
  \def\arraystretch{1.3}
  \setlength\tabcolsep{3mm}
  \begin{tabular}{r|c|c|c|c|}
  \cline{2-5}
  \multicolumn{1}{c|}{}                      & \textbf{BRAM 18K} & \textbf{DSP48E} & \textbf{FF} & \textbf{LUT} \\ \hline
  \multicolumn{1}{|r|}{\textbf{Total used}}       & 12                 & 4,351            & 58,942       & 298,881       \\ \hline
  \multicolumn{1}{|r|}{\textbf{Available}}   & 5,376              & 12,288           & 3,456,000     & 1,728,000      \\ \hline\hline
  \multicolumn{1}{|r|}{\textbf{Utilization}} & 0.22\%            & 35.41\%         & 1.71\%      & 17.30\%       \\ \hline
  \end{tabular}
  \egroup
\end{table}

\indo{Explain which and how the design changes affected the results below}
\indo{|}
\indo{|}
\indo{|}

\begin{figure}[hpt!]
  \centering
  \includegraphics[trim={0cm 0cm 0cm 1cm}, clip, width=0.8\textwidth, center]{../logs/hardware_optimizations.png}
  \caption{Results of the optimization process for the ultra-low latency model.}
  \label{fig:hardware-optimizations}
\end{figure}

\indo{Talk about Pareto front and its meaning, maybe use a roofline model if it makes sense}
\indo{|}
\indo{|}
\indo{|}

\begin{figure}[hpt!]
  \centering
  \includegraphics[trim={0cm 0cm 0cm 1.3cm}, clip, width=0.6\textwidth, center]{../logs/hardware_optimizations_pareto.png}
  \caption{Latency plotted against average resource utilization for the ultra-low latency model configurations.}
  \label{fig:hardware-optimizations-pareto}
\end{figure}


\indo{Verify analytical models for latency/resources - state that each linear and matmul blocks dont share the coefficients as they depend on how the pipelining is done}

\indo{compare results with transformers using hls4ml for point cloud ... that Walkie suggested}

\subsection{Accuracy-Focused Model}

\indo{Talk about grid search for accuracy-focused model as a quick and easy hyperparameter search, that was done mainly to look for simpler designs given very long synthesis, not hardcore tuning accuracy}
\indo{Give estimate of how long is the synthesis and why this is a problem}
\indo{|}
\indo{|}

\begin{figure}[hpt!]
  \centering
  \includegraphics[trim={0cm 0cm 0cm 1cm}, clip, width=1.0\textwidth, center]{../logs/grid_search.png}
  \caption{Grid-search results - squares area proportional to accuracy.}
  \label{fig:grid-search}
\end{figure}

\subsection{Design Space Exploration}



\section{Quantization Results}


\subsection{Quantization-Aware Training}
\indo{Recap how this was done and talk about results}
\indo{Mention float16 doesnt learn anything (acc 20\%) as its range is too small, and we cannot consider normalizing inputs as its real time system}
\indo{Mention problems with fixed-point 32 and reason about both int and frac range being important, give examples at which point which one causes issues (likely input -> int range, after normalization -> frac range)}
\indo{Mention brevitas only gets 34\% accuracy and why this is the case and how it could be solved}
\indo{|}
\indo{|}
\indo{|}

\begin{figure}[hpt!]
  \centering
  \includegraphics[trim={0cm 0cm 0cm 1.2cm}, clip, width=1.0\textwidth, center]{../logs/training_accuracy.png}
  \caption{Performance against epochs for floating-point and fixed-point models.}
  \label{fig:pre-training}
\end{figure}


\subsection{Post-Training Quantization}\label{eval:post-training-quantization}
\indo{State that the results are very promising (64\% bits reduction), how this should influence synthesis}
\indo{prove correlation with how different on average is the next bit width compared to previous vs default (34 bits etc)}
\indo{say how we dont do synthesis due to time limitations, and its mostly no problem as the widhts are linear with hardware resources aside from the situations in which a dsp can be avoided (34 vs 35 bits etc)}
\indo{Maybe talk about how correlation was verified}
\indo{starting with integer or fractional in the search didnt seem to matter in the limited tests}
\indo{Discuss the used parameters (ratio of positive and negative tolerance etc.) and how they affect the results}
\indo{compare with performance of the HAQ that Walkie suggested}
\indo{|}

\begin{figure}[hpt!]
  \centering
  \includegraphics[trim={0cm 0cm 1cm 7.8mm}, clip, width=1.0\textwidth, center]{../logs/bit_width_visualization.png}
  \caption{Visualization of the fixed-point precision of the types used in the accuracy-focused model.}
  \label{fig:post-training-bit-widths}
\end{figure}

\documentclass[a4paper, twoside]{report}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=2.0cm]{geometry}
\usepackage{parskip} % paragraph style with no indentations and spaces between

%% References
\usepackage[nottoc]{tocbibind} % include bibliography in ToC
\usepackage[numbers]{natbib}
\addto\captionsenglish{
  \renewcommand{\bibname}{References}
} % change name from 'Bibliography' to 'References'

\newcommand{\hlsml}[0]{\texttt{hls4ml} }

%% Useful packages
\usepackage{amsmath}
\usepackage{bm}
\usepackage{graphicx}
\usepackage[table,xcdraw]{xcolor}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage[export]{adjustbox}
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{xargs}

% Algorithm description
\usepackage{algorithm}
\usepackage{algpseudocode}

%% Itemize lists with more depth
\usepackage{enumitem}
% \usepackage{pifont}
\usepackage{outlines}
\usepackage{amssymb}
\renewcommand{\labelitemii}{$\circ$}
\renewcommand{\labelitemiii}{$\blacksquare$}
% \renewcommand{\labelitemiv}{\textendash}

% Appendix
\usepackage[toc,page]{appendix}

% Clever references from labels
\usepackage{cleveref}


%% Todo notes
\usepackage[colorinlistoftodos]{todonotes} % todo notes, add [disable] to turn them off
\newcommandx{\indo}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,inline,#1]{#2}}
\newcommandx{\maybe}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,inline,#1]{#2}}
\newcommandx{\todofig}[2][1=]{\todo[linecolor=green,backgroundcolor=green!25,bordercolor=green,inline,#1]{#2}}
% \newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}

%% Auxiliary packages
\usepackage{lipsum} % lorem ipsum

\title{Reconfigurable Acceleration of Transformer Neural Networks with Meta-Programming Strategies for Particle Physics Experiments}
\author{Filip Wojcicki}

\begin{document}
\input{title/title.tex}

\begin{abstract}
  Particle Physics studies the fundamental forces and elementary particles building the Universe. In order to verify the correctness of the theories, countless experiments have to be designed and carefully executed, with the main driving force of the myriads of engineers, physicists and researchers at the Large Hadron Collider (LHC) operated by the European Organization for Nuclear Research (CERN). With the unprecedented experiments' scale comes the challenge of accurate, ultra-low latency decision-making. Transformer Neural Networks (TNN) have been proven to accomplish cutting-edge accuracy in various domains, including classification for jet tagging, which is the target of this project. However, software-centered solution implemented for CPUs and GPUs lack the inference speed needed for real-time particle triggers.
  
  This report proposes two novel TNN-based architectures efficiently mapped to Field-Programmable Gate Arrays (FPGAs). The first one outperforms the current state-of-the-art models' GPU inference capabilities by roughly 1000 \todo{Confirm this number} times while maintaining comparable classification accuracy. The second one trades off some of its speed for accuracy and undergoes a broad design-space exploration, which involves both pre-training and post-training quantization. The latter one leverages a custom-developed tool chain that augments existing solutions in terms of granularity and ease-of-use while following an innovative algorithm for relatively quick convergence.

  In this project, several recently researched neural network components are designed to target FPGAs using High-Level Synthesis (HLS). The resulting open-sourced building blocks are both highly customizable and abstract, and aim to bridge the gap between hardware and software development, effectively reducing the time and complexity needed for creating efficient neural network hardware accelerators.
\end{abstract}

\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
I would like to express my gratitude to Professor Wayne Luk for his guidance, insightful suggestions and constant encouragement throughout the project.
\newline

I would like to thank Professor Tapper for giving me a different view on the project's meaning and providing with the behind-the-scenes information about the LHC.
\newline

I want to thank Zhiqiang Que for his continuous technical support, our weekly meetings and always being available to answer any of my questions.
\newline

Lastly, I am very grateful for my family whose support was invaluable during this project and the degree as a whole.
\end{abstract}

{\hypersetup{linkcolor=black}
  \tableofcontents
  \listoffigures
  \begingroup % way to display both figure and table lists together
    \let\clearpage\relax
    \listoftables
  \endgroup
}

\input{introduction/introduction}
\input{background/background}
\input{models/models}
\input{quantization/quantization}
% \input{project/project}
% \input{implementation/implementation}
\input{evaluation/evaluation}
\input{conclusion/conclusion}

\bibliographystyle{unsrtnat}
\bibliography{references/references}

\input{appendix/appendix}

\listoftodos[Notes]

\end{document}
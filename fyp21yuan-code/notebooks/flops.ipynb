{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293a04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "import nn.model.net as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea705d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_constituent_base = torch.jit.load('experiments/constituent_base/best.script.pth', map_location='cpu').eval()\n",
    "model_constituent_cluster = torch.jit.load('experiments/constituent_cluster/best.script.pth', map_location='cpu').eval()\n",
    "model_constituent_graph = torch.jit.load('experiments/constituent_graph/best.script.pth', map_location='cpu').eval()\n",
    "model_constituent_small = torch.jit.load('experiments/constituent_perceiver_3_64/best.script.pth', map_location='cpu').eval()\n",
    "model_constituent_tiny = torch.jit.load('experiments/constituent_perceiver_1/best.script.pth', map_location='cpu').eval()\n",
    "model_constituent_tiny_recurrent = torch.jit.load('experiments/constituent_perceiver_recurrent/best.script.pth', map_location='cpu').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3f2910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_constituent_base = net.ConstituentNet(embbed_dim=128, num_transformers=3)\n",
    "model_constituent_cluster = net.ConstituentNetCluster(embbed_dim=128, num_transformers=3, num_clusters=4)\n",
    "model_constituent_graph = net.ConstituentNetGraph()\n",
    "model_constituent_small = net.ConstituentNetPerceiver(embbed_dim=16, num_embbeds=64, num_perceivers=3, num_heads=1, num_latent_heads=1)\n",
    "model_constituent_tiny = net.ConstituentNetPerceiver(embbed_dim=16, num_embbeds=32, num_perceivers=1, num_heads=1, num_latent_heads=1)\n",
    "model_constituent_tiny_recurrent = net.ConstituentNetPerceiverRecurrent(embbed_dim=16, num_embbeds=32, num_perceivers=5, num_heads=1, num_latent_heads=1, num_latent_transformers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b6dc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n",
      "Unsupported operator aten::div encountered 3 time(s)\n",
      "Unsupported operator aten::softmax encountered 3 time(s)\n",
      "Unsupported operator aten::add encountered 6 time(s)\n",
      "Unsupported operator aten::silu encountered 6 time(s)\n",
      "Unsupported operator aten::log_softmax encountered 1 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1553000432.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand((32, 100, 16))\n",
    "flops = FlopCountAnalysis(model_constituent_base, inp)\n",
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54714d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::pow encountered 9 time(s)\n",
      "Unsupported operator aten::div encountered 9 time(s)\n",
      "Unsupported operator aten::softmax encountered 9 time(s)\n",
      "Unsupported operator aten::add encountered 15 time(s)\n",
      "Unsupported operator aten::silu encountered 12 time(s)\n",
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::log_softmax encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "norm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1928356524.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand((32, 100, 16))\n",
    "flops = FlopCountAnalysis(model_constituent_cluster, inp)\n",
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32d93501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::softmax encountered 1 time(s)\n",
      "Unsupported operator aten::log_softmax encountered 1 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42139648"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand((32, 100, 16))\n",
    "flops = FlopCountAnalysis(model_constituent_graph, inp)\n",
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "478406ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::pow encountered 9 time(s)\n",
      "Unsupported operator aten::div encountered 9 time(s)\n",
      "Unsupported operator aten::softmax encountered 9 time(s)\n",
      "Unsupported operator aten::add encountered 15 time(s)\n",
      "Unsupported operator aten::silu encountered 12 time(s)\n",
      "Unsupported operator aten::log_softmax encountered 1 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82640272.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand((32, 100, 16))\n",
    "flops = FlopCountAnalysis(model_constituent_small, inp)\n",
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94586341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::repeat encountered 1 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n",
      "Unsupported operator aten::div encountered 3 time(s)\n",
      "Unsupported operator aten::softmax encountered 3 time(s)\n",
      "Unsupported operator aten::add encountered 5 time(s)\n",
      "Unsupported operator aten::silu encountered 4 time(s)\n",
      "Unsupported operator aten::log_softmax encountered 1 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12551192.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand((32, 100, 16))\n",
    "flops = FlopCountAnalysis(model_constituent_tiny, inp)\n",
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43588d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::repeat encountered 2 time(s)\n",
      "Unsupported operator aten::pow encountered 15 time(s)\n",
      "Unsupported operator aten::div encountered 15 time(s)\n",
      "Unsupported operator aten::softmax encountered 15 time(s)\n",
      "Unsupported operator aten::add encountered 30 time(s)\n",
      "Unsupported operator aten::mul encountered 10 time(s)\n",
      "Unsupported operator aten::unsafe_chunk encountered 10 time(s)\n",
      "Unsupported operator aten::add_ encountered 15 time(s)\n",
      "Unsupported operator aten::sigmoid_ encountered 10 time(s)\n",
      "Unsupported operator aten::mul_ encountered 10 time(s)\n",
      "Unsupported operator aten::tanh_ encountered 5 time(s)\n",
      "Unsupported operator aten::sub encountered 5 time(s)\n",
      "Unsupported operator aten::silu encountered 20 time(s)\n",
      "Unsupported operator aten::log_softmax encountered 1 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68981880.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand((32, 100, 16))\n",
    "flops = FlopCountAnalysis(model_constituent_tiny_recurrent, inp)\n",
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4844ec02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=ConstituentNetPerceiverRecurrent\n",
       "  (perceiver): RecursiveScriptModule(\n",
       "    original_name=PerceiverDynamicQuery\n",
       "    (cross_transformer): RecursiveScriptModule(\n",
       "      original_name=CrossTransformerDynamicQuery\n",
       "      (self_attention): RecursiveScriptModule(\n",
       "        original_name=SelfAttention\n",
       "        (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (out): RecursiveScriptModule(original_name=Linear)\n",
       "      )\n",
       "      (cross_attention): RecursiveScriptModule(\n",
       "        original_name=AttentionDynamicQuery\n",
       "        (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "        (queries): RecursiveScriptModule(original_name=GRUCell)\n",
       "        (keys): RecursiveScriptModule(original_name=Linear)\n",
       "        (values): RecursiveScriptModule(original_name=Linear)\n",
       "        (out): RecursiveScriptModule(original_name=Linear)\n",
       "      )\n",
       "      (linear): RecursiveScriptModule(\n",
       "        original_name=Sequential\n",
       "        (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "        (1): RecursiveScriptModule(original_name=SiLU)\n",
       "        (2): RecursiveScriptModule(original_name=Linear)\n",
       "        (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "        (4): RecursiveScriptModule(original_name=SiLU)\n",
       "        (5): RecursiveScriptModule(original_name=Linear)\n",
       "      )\n",
       "      (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "    )\n",
       "    (transformers): RecursiveScriptModule(\n",
       "      original_name=ModuleList\n",
       "      (0): RecursiveScriptModule(\n",
       "        original_name=Transformer\n",
       "        (self_attention): RecursiveScriptModule(\n",
       "          original_name=SelfAttention\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (linear): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (1): RecursiveScriptModule(original_name=SiLU)\n",
       "          (2): RecursiveScriptModule(original_name=Linear)\n",
       "          (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (4): RecursiveScriptModule(original_name=SiLU)\n",
       "          (5): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (perceivers): RecursiveScriptModule(\n",
       "    original_name=ModuleList\n",
       "    (0): RecursiveScriptModule(\n",
       "      original_name=PerceiverDynamicQuery\n",
       "      (cross_transformer): RecursiveScriptModule(\n",
       "        original_name=CrossTransformerDynamicQuery\n",
       "        (self_attention): RecursiveScriptModule(\n",
       "          original_name=SelfAttention\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (cross_attention): RecursiveScriptModule(\n",
       "          original_name=AttentionDynamicQuery\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (queries): RecursiveScriptModule(original_name=GRUCell)\n",
       "          (keys): RecursiveScriptModule(original_name=Linear)\n",
       "          (values): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (linear): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (1): RecursiveScriptModule(original_name=SiLU)\n",
       "          (2): RecursiveScriptModule(original_name=Linear)\n",
       "          (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (4): RecursiveScriptModule(original_name=SiLU)\n",
       "          (5): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (transformers): RecursiveScriptModule(\n",
       "        original_name=ModuleList\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=Transformer\n",
       "          (self_attention): RecursiveScriptModule(\n",
       "            original_name=SelfAttention\n",
       "            (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "            (out): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (linear): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (1): RecursiveScriptModule(original_name=SiLU)\n",
       "            (2): RecursiveScriptModule(original_name=Linear)\n",
       "            (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (4): RecursiveScriptModule(original_name=SiLU)\n",
       "            (5): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): RecursiveScriptModule(\n",
       "      original_name=PerceiverDynamicQuery\n",
       "      (cross_transformer): RecursiveScriptModule(\n",
       "        original_name=CrossTransformerDynamicQuery\n",
       "        (self_attention): RecursiveScriptModule(\n",
       "          original_name=SelfAttention\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (cross_attention): RecursiveScriptModule(\n",
       "          original_name=AttentionDynamicQuery\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (queries): RecursiveScriptModule(original_name=GRUCell)\n",
       "          (keys): RecursiveScriptModule(original_name=Linear)\n",
       "          (values): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (linear): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (1): RecursiveScriptModule(original_name=SiLU)\n",
       "          (2): RecursiveScriptModule(original_name=Linear)\n",
       "          (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (4): RecursiveScriptModule(original_name=SiLU)\n",
       "          (5): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (transformers): RecursiveScriptModule(\n",
       "        original_name=ModuleList\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=Transformer\n",
       "          (self_attention): RecursiveScriptModule(\n",
       "            original_name=SelfAttention\n",
       "            (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "            (out): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (linear): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (1): RecursiveScriptModule(original_name=SiLU)\n",
       "            (2): RecursiveScriptModule(original_name=Linear)\n",
       "            (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (4): RecursiveScriptModule(original_name=SiLU)\n",
       "            (5): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): RecursiveScriptModule(\n",
       "      original_name=PerceiverDynamicQuery\n",
       "      (cross_transformer): RecursiveScriptModule(\n",
       "        original_name=CrossTransformerDynamicQuery\n",
       "        (self_attention): RecursiveScriptModule(\n",
       "          original_name=SelfAttention\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (cross_attention): RecursiveScriptModule(\n",
       "          original_name=AttentionDynamicQuery\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (queries): RecursiveScriptModule(original_name=GRUCell)\n",
       "          (keys): RecursiveScriptModule(original_name=Linear)\n",
       "          (values): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (linear): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (1): RecursiveScriptModule(original_name=SiLU)\n",
       "          (2): RecursiveScriptModule(original_name=Linear)\n",
       "          (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (4): RecursiveScriptModule(original_name=SiLU)\n",
       "          (5): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (transformers): RecursiveScriptModule(\n",
       "        original_name=ModuleList\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=Transformer\n",
       "          (self_attention): RecursiveScriptModule(\n",
       "            original_name=SelfAttention\n",
       "            (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "            (out): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (linear): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (1): RecursiveScriptModule(original_name=SiLU)\n",
       "            (2): RecursiveScriptModule(original_name=Linear)\n",
       "            (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (4): RecursiveScriptModule(original_name=SiLU)\n",
       "            (5): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): RecursiveScriptModule(\n",
       "      original_name=PerceiverDynamicQuery\n",
       "      (cross_transformer): RecursiveScriptModule(\n",
       "        original_name=CrossTransformerDynamicQuery\n",
       "        (self_attention): RecursiveScriptModule(\n",
       "          original_name=SelfAttention\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (cross_attention): RecursiveScriptModule(\n",
       "          original_name=AttentionDynamicQuery\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (queries): RecursiveScriptModule(original_name=GRUCell)\n",
       "          (keys): RecursiveScriptModule(original_name=Linear)\n",
       "          (values): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (linear): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (1): RecursiveScriptModule(original_name=SiLU)\n",
       "          (2): RecursiveScriptModule(original_name=Linear)\n",
       "          (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (4): RecursiveScriptModule(original_name=SiLU)\n",
       "          (5): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (transformers): RecursiveScriptModule(\n",
       "        original_name=ModuleList\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=Transformer\n",
       "          (self_attention): RecursiveScriptModule(\n",
       "            original_name=SelfAttention\n",
       "            (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "            (out): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (linear): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (1): RecursiveScriptModule(original_name=SiLU)\n",
       "            (2): RecursiveScriptModule(original_name=Linear)\n",
       "            (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (4): RecursiveScriptModule(original_name=SiLU)\n",
       "            (5): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): RecursiveScriptModule(\n",
       "      original_name=PerceiverDynamicQuery\n",
       "      (cross_transformer): RecursiveScriptModule(\n",
       "        original_name=CrossTransformerDynamicQuery\n",
       "        (self_attention): RecursiveScriptModule(\n",
       "          original_name=SelfAttention\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (cross_attention): RecursiveScriptModule(\n",
       "          original_name=AttentionDynamicQuery\n",
       "          (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (queries): RecursiveScriptModule(original_name=GRUCell)\n",
       "          (keys): RecursiveScriptModule(original_name=Linear)\n",
       "          (values): RecursiveScriptModule(original_name=Linear)\n",
       "          (out): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (linear): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (1): RecursiveScriptModule(original_name=SiLU)\n",
       "          (2): RecursiveScriptModule(original_name=Linear)\n",
       "          (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "          (4): RecursiveScriptModule(original_name=SiLU)\n",
       "          (5): RecursiveScriptModule(original_name=Linear)\n",
       "        )\n",
       "        (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (transformers): RecursiveScriptModule(\n",
       "        original_name=ModuleList\n",
       "        (0): RecursiveScriptModule(\n",
       "          original_name=Transformer\n",
       "          (self_attention): RecursiveScriptModule(\n",
       "            original_name=SelfAttention\n",
       "            (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "            (out): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (linear): RecursiveScriptModule(\n",
       "            original_name=Sequential\n",
       "            (0): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (1): RecursiveScriptModule(original_name=SiLU)\n",
       "            (2): RecursiveScriptModule(original_name=Linear)\n",
       "            (3): RecursiveScriptModule(original_name=LayerNorm)\n",
       "            (4): RecursiveScriptModule(original_name=SiLU)\n",
       "            (5): RecursiveScriptModule(original_name=Linear)\n",
       "          )\n",
       "          (dropout): RecursiveScriptModule(original_name=Dropout)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_layer): RecursiveScriptModule(\n",
       "    original_name=Sequential\n",
       "    (0): RecursiveScriptModule(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_constituent_tiny_recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888a8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
